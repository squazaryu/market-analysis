#!/usr/bin/env python3
"""
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ë–ü–ò–§ –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞ –¶–ë
"""

import pandas as pd
import re
from pathlib import Path

def extract_bpif_details():
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ë–ü–ò–§"""
    
    # –ß–∏—Ç–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –ë–ü–ò–§
    bpif_file = Path("cbr_bpif_by_name.csv")
    
    if not bpif_file.exists():
        print("‚ùå –§–∞–π–ª —Å –ë–ü–ò–§ –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ parse_cbr_pif_registry.py")
        return None
    
    try:
        df = pd.read_csv(bpif_file, encoding='utf-8')
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –ë–ü–ò–§ –∏–∑ —Ñ–∞–π–ª–∞")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ë–ü–ò–§:")
        for i, col in enumerate(df.columns):
            non_null_count = df[col].notna().sum()
            print(f"   {i+1:2d}. {col} (–∑–∞–ø–æ–ª–Ω–µ–Ω–æ: {non_null_count}/{len(df)})")
        
        # –ò—â–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        print(f"\nüîç –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç–æ–ª–±—Ü–æ–≤:")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Å—Ç–æ–ª–±–µ—Ü –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        useful_columns = {}
        
        for col in df.columns:
            if col.startswith('Unnamed'):
                # –°–º–æ—Ç—Ä–∏–º –Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                unique_vals = df[col].dropna().unique()
                
                if len(unique_vals) > 0 and len(unique_vals) < len(df):
                    sample_vals = list(unique_vals[:5])
                    print(f"\n   üìã {col}:")
                    print(f"      –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {len(unique_vals)}")
                    print(f"      –ü—Ä–∏–º–µ—Ä—ã: {sample_vals}")
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
                    content_type = identify_content_type(unique_vals)
                    if content_type:
                        print(f"      –¢–∏–ø —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {content_type}")
                        useful_columns[col] = content_type
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –ë–ü–ò–§
        print(f"\nüìä –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –ë–ü–ò–§...")
        
        structured_data = []
        
        for idx, row in df.iterrows():
            bpif_info = {
                'id': idx + 1,
                'raw_data': {}
            }
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–µ–ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ
            for col in df.columns:
                if pd.notna(row[col]) and str(row[col]).strip():
                    bpif_info['raw_data'][col] = str(row[col]).strip()
            
            structured_data.append(bpif_info)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ç–∏–∫–µ—Ä—ã –∏ –Ω–∞–∑–≤–∞–Ω–∏—è
        print(f"\nüéØ –ü–æ–∏—Å–∫ —Ç–∏–∫–µ—Ä–æ–≤ –∏ –Ω–∞–∑–≤–∞–Ω–∏–π...")
        
        tickers_found = []
        names_found = []
        
        for item in structured_data[:10]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
            print(f"\nüìã –ë–ü–ò–§ #{item['id']}:")
            
            potential_ticker = None
            potential_name = None
            
            for col, value in item['raw_data'].items():
                print(f"   {col}: {value}")
                
                # –ò—â–µ–º —Ç–∏–∫–µ—Ä—ã (–æ–±—ã—á–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–µ –∫–æ–¥—ã –∏–∑ –±—É–∫–≤)
                if re.match(r'^[A-Z]{3,6}$', value):
                    potential_ticker = value
                
                # –ò—â–µ–º –ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è (–¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º)
                if len(value) > 20 and any(word in value.lower() for word in ['—Ñ–æ–Ω–¥', '–ø–∞–µ–≤–æ–π', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π']):
                    potential_name = value
            
            if potential_ticker:
                tickers_found.append(potential_ticker)
                print(f"   üéØ –í–æ–∑–º–æ–∂–Ω—ã–π —Ç–∏–∫–µ—Ä: {potential_ticker}")
            
            if potential_name:
                names_found.append(potential_name)
                print(f"   üìù –í–æ–∑–º–æ–∂–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {potential_name[:100]}...")
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ë–ü–ò–§ –≤ —Ä–µ–µ—Å—Ç—Ä–µ: {len(structured_data)}")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤: {len(set(tickers_found))}")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–π: {len(set(names_found))}")
        
        if tickers_found:
            print(f"\nüè∑Ô∏è –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∏–∫–µ—Ä—ã: {list(set(tickers_found))}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        output_file = "bpif_structured_data.csv"
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        output_rows = []
        for item in structured_data:
            row = {'id': item['id']}
            for col, value in item['raw_data'].items():
                row[col] = value
            output_rows.append(row)
        
        output_df = pd.DataFrame(output_rows)
        output_df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"\nüíæ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        
        return structured_data
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return None

def identify_content_type(values):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º"""
    
    if values is None or len(values) == 0:
        return None
    
    sample = [str(v) for v in values[:10] if pd.notna(v)]
    
    if not sample:
        return None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–∏–∫–µ—Ä—ã (–∫–æ—Ä–æ—Ç–∫–∏–µ –∫–æ–¥—ã –∏–∑ –±—É–∫–≤)
    if all(re.match(r'^[A-Z]{3,6}$', s) for s in sample):
        return "–í–æ–∑–º–æ–∂–Ω—ã–µ —Ç–∏–∫–µ—Ä—ã"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–æ–Ω–¥–æ–≤
    if any(len(s) > 20 and any(word in s.lower() for word in ['—Ñ–æ–Ω–¥', '–ø–∞–µ–≤–æ–π', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π']) for s in sample):
        return "–ù–∞–∑–≤–∞–Ω–∏—è —Ñ–æ–Ω–¥–æ–≤"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥–∞—Ç—ã
    if any(re.match(r'\d{2}\.\d{2}\.\d{4}', s) for s in sample):
        return "–î–∞—Ç—ã"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —á–∏—Å–ª–∞
    if all(re.match(r'^\d+(\.\d+)?$', s) for s in sample):
        return "–ß–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–æ–¥—ã/–Ω–æ–º–µ—Ä–∞
    if all(len(s) < 20 and re.match(r'^[A-Z0-9\-]+$', s) for s in sample):
        return "–ö–æ–¥—ã/–Ω–æ–º–µ—Ä–∞"
    
    return "–¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"

if __name__ == "__main__":
    data = extract_bpif_details()
    
    if data:
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
        print("üìù –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∏–∫–µ—Ä—ã")
        print("   2. –°–æ–ø–æ—Å—Ç–∞–≤—å—Ç–µ —Å –¥–∞–Ω–Ω—ã–º–∏ MOEX")
        print("   3. –û–±–Ω–æ–≤–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö")