#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞ –∏ —Ç—Ä–µ–Ω–¥–æ–≤ –¥–ª—è —Ä—ã–Ω–∫–∞ –ë–ü–ò–§
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –¥–≤–∏–∂–µ–Ω–∏–µ –¥–µ–Ω–µ–≥ –º–µ–∂–¥—É —Å–µ–∫—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import json
from pathlib import Path
from full_fund_compositions import get_fund_category, FUND_COMPOSITIONS
from historical_data_manager import HistoricalDataManager

class CapitalFlowAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞ –º–µ–∂–¥—É —Å–µ–∫—Ç–æ—Ä–∞–º–∏ ETF"""
    
    def __init__(self, etf_data: pd.DataFrame, historical_manager: Optional[HistoricalDataManager] = None):
        self.etf_data = etf_data
        self.historical_manager = historical_manager or HistoricalDataManager()
        self.sector_mapping = self._create_sector_mapping()
        
    def _create_sector_mapping(self) -> Dict[str, str]:
        """–°–æ–∑–¥–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ ETF –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–æ–≤"""
        sector_map = {}
        
        # –°–Ω–∞—á–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–æ–≤
        for _, row in self.etf_data.iterrows():
            ticker = row['ticker']
            isin = row.get('isin', '')
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            fund_info = get_fund_category(isin)
            
            if fund_info['category'] != '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ':
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                sector_map[ticker] = f"{fund_info['category']} ({fund_info['subcategory']})"
            else:
                # Fallback: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–æ–Ω–¥–æ–≤
                full_name = str(row.get('full_name', '')).lower()
                short_name = str(row.get('short_name', '')).lower()
                name = str(row.get('name', '')).lower()
                
                combined_name = f"{full_name} {short_name} {name}".lower()
                
                # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                if any(word in combined_name for word in ['–æ–±–ª–∏–≥', '–æ–±–ª ', 'bond', '–∫—É–ø–æ–Ω']):
                    sector_map[ticker] = '–û–±–ª–∏–≥–∞—Ü–∏–∏ (–°–º–µ—à–∞–Ω–Ω—ã–µ)'
                elif any(word in combined_name for word in ['–∑–æ–ª–æ—Ç', 'gold', '–¥—Ä–∞–≥']):
                    sector_map[ticker] = '–î—Ä–∞–≥–æ—Ü–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–ª–ª—ã (–ó–æ–ª–æ—Ç–æ)'
                elif any(word in combined_name for word in ['–≤–∞–ª—é—Ç', '–¥–æ–ª–ª–∞—Ä', '–µ–≤—Ä–æ', '—é–∞–Ω—å', 'currency']):
                    sector_map[ticker] = '–í–∞–ª—é—Ç–Ω—ã–µ (–°–º–µ—à–∞–Ω–Ω—ã–µ)'
                elif any(word in combined_name for word in ['–∏—Ç ', '—Ç–µ—Ö–Ω–æ–ª–æ–≥', 'tech', '—Å–æ—Ñ—Ç', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç']):
                    sector_map[ticker] = '–ê–∫—Ü–∏–∏ (–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)'
                elif any(word in combined_name for word in ['—ç–Ω–µ—Ä–≥', '–Ω–µ—Ñ—Ç', '–≥–∞–∑', 'energy']):
                    sector_map[ticker] = '–ê–∫—Ü–∏–∏ (–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞)'
                elif any(word in combined_name for word in ['—Ñ–∏–Ω–∞–Ω—Å', '–±–∞–Ω–∫', '—Å—Ç—Ä–∞—Ö', 'finance']):
                    sector_map[ticker] = '–ê–∫—Ü–∏–∏ (–§–∏–Ω–∞–Ω—Å—ã)'
                elif any(word in combined_name for word in ['–∏–Ω–¥–µ–∫—Å', '—à–∏—Ä–æ–∫', '—Ä—ã–Ω–æ–∫', '—Ä—Ç—Å', '–º–º–≤–±', '–º–æ—Å–±–∏—Ä–∂']):
                    sector_map[ticker] = '–ê–∫—Ü–∏–∏ (–®–∏—Ä–æ–∫–∏–π —Ä—ã–Ω–æ–∫)'
                elif any(word in combined_name for word in ['–≥–æ–ª—É–±', 'blue', '–ª–∏–¥–µ—Ä', '—Ç–æ–ø']):
                    sector_map[ticker] = '–ê–∫—Ü–∏–∏ (–ì–æ–ª—É–±—ã–µ —Ñ–∏—à–∫–∏)'
                elif any(word in combined_name for word in ['–∞–Ω—Ç–∏–∏–Ω—Ñ–ª—è—Ü', '–∑–∞—â–∏—Ç', '—Å—Ç–∞–±–∏–ª']):
                    sector_map[ticker] = '–ó–∞—â–∏—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã (–°–º–µ—à–∞–Ω–Ω—ã–µ)'
                else:
                    sector_map[ticker] = '–°–º–µ—à–∞–Ω–Ω—ã–µ/–ü—Ä–æ—á–∏–µ'
                
        return sector_map
    
    def calculate_sector_flows(self) -> pd.DataFrame:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ç–æ–∫–∏ –∫–∞–ø–∏—Ç–∞–ª–∞ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ç–æ—Ä –∫ –∫–∞–∂–¥–æ–º—É ETF
        self.etf_data['sector'] = self.etf_data['ticker'].map(
            lambda x: self.sector_mapping.get(x, '–ü—Ä–æ—á–∏–µ')
        )
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º
        sector_flows = self.etf_data.groupby('sector').agg({
            'avg_daily_volume': 'sum',
            'market_cap': 'sum', 
            'annual_return': 'mean',
            'volatility': 'mean',
            'ticker': 'count'
        }).round(2)
        
        sector_flows.columns = [
            'total_volume', 'total_market_cap', 'avg_return', 
            'avg_volatility', 'etf_count'
        ]
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–æ–ª—é –∫–∞–∂–¥–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞
        total_volume = sector_flows['total_volume'].sum()
        total_market_cap = sector_flows['total_market_cap'].sum()
        
        sector_flows['volume_share'] = (sector_flows['total_volume'] / total_volume * 100).round(1)
        sector_flows['market_cap_share'] = (sector_flows['total_market_cap'] / total_market_cap * 100).round(1)
        
        return sector_flows.sort_values('total_volume', ascending=False)
    
    def detect_risk_sentiment(self) -> Dict[str, any]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (risk-on/risk-off)"""
        
        sector_flows = self.calculate_sector_flows()
        
        # –ó–∞—â–∏—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã (risk-off)
        defensive_sectors = ['–û–±–ª–∏–≥–∞—Ü–∏–∏', '–ó–æ–ª–æ—Ç–æ', '–í–∞–ª—é—Ç–Ω—ã–µ']
        # –†–∏—Å–∫–æ–≤—ã–µ –∞–∫—Ç–∏–≤—ã (risk-on) 
        risky_sectors = ['–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '–ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π —Å–µ–∫—Ç–æ—Ä', '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞']
        
        defensive_volume = sector_flows[
            sector_flows.index.isin(defensive_sectors)
        ]['volume_share'].sum()
        
        risky_volume = sector_flows[
            sector_flows.index.isin(risky_sectors)
        ]['volume_share'].sum()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        if defensive_volume > risky_volume * 1.5:
            sentiment = "Risk-Off"
            confidence = min(95, defensive_volume / max(risky_volume, 0.1) * 30)
        elif risky_volume > defensive_volume * 1.5:
            sentiment = "Risk-On" 
            confidence = min(95, risky_volume / max(defensive_volume, 0.1) * 30)
        else:
            sentiment = "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π"
            confidence = 50
            
        return {
            'sentiment': sentiment,
            'confidence': round(confidence, 1),
            'defensive_share': round(defensive_volume, 1),
            'risky_share': round(risky_volume, 1),
            'ratio': round(defensive_volume / max(risky_volume, 0.1), 2)
        }
    
    def analyze_sector_momentum(self) -> pd.DataFrame:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–º–µ–Ω—Ç—É–º –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        
        sector_flows = self.calculate_sector_flows()
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –º–æ–º–µ–Ω—Ç—É–º–∞
        sector_flows['momentum_score'] = (
            sector_flows['avg_return'] * 0.4 +  # –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
            (100 - sector_flows['avg_volatility']) * 0.3 +  # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
            sector_flows['volume_share'] * 0.3  # –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤
        ).round(1)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –º–æ–º–µ–Ω—Ç—É–º
        def classify_momentum(score):
            if score >= 70:
                return "–°–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç"
            elif score >= 50:
                return "–£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç"
            elif score >= 30:
                return "–°—Ç–∞–≥–Ω–∞—Ü–∏—è"
            else:
                return "–°–Ω–∏–∂–µ–Ω–∏–µ"
                
        sector_flows['momentum_trend'] = sector_flows['momentum_score'].apply(classify_momentum)
        
        return sector_flows.sort_values('momentum_score', ascending=False)
    
    def detect_flow_anomalies(self) -> List[Dict]:
        """–í—ã—è–≤–ª—è–µ—Ç –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø–æ—Ç–æ–∫–∏ –∫–∞–ø–∏—Ç–∞–ª–∞"""
        
        sector_flows = self.calculate_sector_flows()
        anomalies = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–æ–º–∞–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–µ –æ–±—ä–µ–º—ã
        volume_threshold = sector_flows['volume_share'].mean() + 2 * sector_flows['volume_share'].std()
        
        for sector, data in sector_flows.iterrows():
            if data['volume_share'] > volume_threshold:
                anomalies.append({
                    'type': '–í—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º',
                    'sector': sector,
                    'value': data['volume_share'],
                    'threshold': round(volume_threshold, 1),
                    'severity': '–í—ã—Å–æ–∫–∞—è' if data['volume_share'] > volume_threshold * 1.5 else '–°—Ä–µ–¥–Ω—è—è'
                })
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–æ–º–∞–ª—å–Ω—É—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        return_threshold = abs(sector_flows['avg_return'].mean()) + 2 * sector_flows['avg_return'].std()
        
        for sector, data in sector_flows.iterrows():
            if abs(data['avg_return']) > return_threshold:
                anomalies.append({
                    'type': '–ê–Ω–æ–º–∞–ª—å–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å',
                    'sector': sector, 
                    'value': data['avg_return'],
                    'threshold': round(return_threshold, 1),
                    'severity': '–í—ã—Å–æ–∫–∞—è' if abs(data['avg_return']) > return_threshold * 1.5 else '–°—Ä–µ–¥–Ω—è—è'
                })
                
        return sorted(anomalies, key=lambda x: x['value'], reverse=True)
    
    def generate_flow_insights(self) -> Dict[str, any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Å–∞–π—Ç—ã –ø–æ –ø–æ—Ç–æ–∫–∞–º –∫–∞–ø–∏—Ç–∞–ª–∞"""
        
        sector_flows = self.calculate_sector_flows()
        sentiment = self.detect_risk_sentiment()
        momentum = self.analyze_sector_momentum()
        anomalies = self.detect_flow_anomalies()
        
        # –¢–æ–ø —Å–µ–∫—Ç–æ—Ä—ã –ø–æ –æ–±—ä–µ–º—É
        top_sectors = sector_flows.head(3).index.tolist()
        
        # –°–µ–∫—Ç–æ—Ä—ã —Å –ª—É—á—à–∏–º –º–æ–º–µ–Ω—Ç—É–º–æ–º
        momentum_leaders = momentum.head(3).index.tolist()
        
        insights = {
            'market_sentiment': sentiment,
            'top_volume_sectors': top_sectors,
            'momentum_leaders': momentum_leaders,
            'total_anomalies': len(anomalies),
            'critical_anomalies': len([a for a in anomalies if a['severity'] == '–í—ã—Å–æ–∫–∞—è']),
            'sector_count': len(sector_flows),
            'analysis_timestamp': datetime.now().isoformat()
        }
        
        return insights
    
    def analyze_fund_flows(self) -> pd.DataFrame:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Ç–æ–∫–∏ –º–µ–∂–¥—É –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ñ–æ–Ω–¥–∞–º–∏"""
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–æ–Ω–¥–∞—Ö
        fund_flows = self.etf_data.copy()
        fund_flows['sector'] = fund_flows['ticker'].map(
            lambda x: self.sector_mapping.get(x, '–°–º–µ—à–∞–Ω–Ω—ã–µ/–ü—Ä–æ—á–∏–µ')
        )
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–Ω–¥–∞
        fund_flows['flow_score'] = (
            fund_flows['avg_daily_volume'] / fund_flows['avg_daily_volume'].max() * 50 +
            abs(fund_flows['annual_return']) / abs(fund_flows['annual_return']).max() * 30 +
            (100 - fund_flows['volatility']) / 100 * 20
        ).round(1)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–∞ (–ø—Ä–∏—Ç–æ–∫/–æ—Ç—Ç–æ–∫)
        fund_flows['flow_direction'] = fund_flows.apply(lambda row: 
            '–ü—Ä–∏—Ç–æ–∫' if row['annual_return'] > 0 and row['avg_daily_volume'] > fund_flows['avg_daily_volume'].median()
            else '–û—Ç—Ç–æ–∫' if row['annual_return'] < 0 and row['avg_daily_volume'] > fund_flows['avg_daily_volume'].median()
            else '–°—Ç–∞–±–∏–ª—å–Ω—ã–π', axis=1
        )
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—ä–µ–º—É —Ç–æ—Ä–≥–æ–≤
        fund_flows = fund_flows.sort_values('avg_daily_volume', ascending=False)
        
        return fund_flows[['ticker', 'full_name', 'sector', 'avg_daily_volume', 
                          'annual_return', 'volatility', 'flow_score', 'flow_direction']]
    
    def detect_sector_rotation(self) -> Dict[str, any]:
        """–í—ã—è–≤–ª—è–µ—Ç —Ä–æ—Ç–∞—Ü–∏—é –º–µ–∂–¥—É —Å–µ–∫—Ç–æ—Ä–∞–º–∏"""
        
        sector_flows = self.calculate_sector_flows()
        fund_flows = self.analyze_fund_flows()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º
        inflow_sectors = []
        outflow_sectors = []
        
        for sector in sector_flows.index:
            sector_funds = fund_flows[fund_flows['sector'] == sector]
            
            if len(sector_funds) > 0:
                inflow_count = len(sector_funds[sector_funds['flow_direction'] == '–ü—Ä–∏—Ç–æ–∫'])
                outflow_count = len(sector_funds[sector_funds['flow_direction'] == '–û—Ç—Ç–æ–∫'])
                total_volume = sector_funds['avg_daily_volume'].sum()
                
                if inflow_count > outflow_count and total_volume > 0:
                    inflow_sectors.append({
                        'sector': sector,
                        'net_flow': inflow_count - outflow_count,
                        'volume': total_volume,
                        'funds_count': len(sector_funds)
                    })
                elif outflow_count > inflow_count:
                    outflow_sectors.append({
                        'sector': sector,
                        'net_flow': outflow_count - inflow_count,
                        'volume': total_volume,
                        'funds_count': len(sector_funds)
                    })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∏–ª–µ –ø–æ—Ç–æ–∫–∞
        inflow_sectors = sorted(inflow_sectors, key=lambda x: x['net_flow'], reverse=True)
        outflow_sectors = sorted(outflow_sectors, key=lambda x: x['net_flow'], reverse=True)
        
        return {
            'inflow_sectors': inflow_sectors[:5],  # –¢–æ–ø-5 —Å–µ–∫—Ç–æ—Ä–æ–≤ —Å –ø—Ä–∏—Ç–æ–∫–æ–º
            'outflow_sectors': outflow_sectors[:5],  # –¢–æ–ø-5 —Å–µ–∫—Ç–æ—Ä–æ–≤ —Å –æ—Ç—Ç–æ–∫–æ–º
            'rotation_strength': len(inflow_sectors) + len(outflow_sectors),
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def get_detailed_fund_info(self) -> pd.DataFrame:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–∞–≤–∞—Ö —Ñ–æ–Ω–¥–æ–≤"""
        
        detailed_info = []
        
        for _, row in self.etf_data.iterrows():
            ticker = row['ticker']
            isin = row.get('isin', '')
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            fund_info = get_fund_category(isin)
            
            detailed_info.append({
                'ticker': ticker,
                'isin': isin,
                'full_name': row.get('full_name', ''),
                'category': fund_info['category'],
                'subcategory': fund_info['subcategory'],
                'risk_level': fund_info['risk_level'],
                'investment_style': fund_info['investment_style'],
                'avg_daily_volume': row.get('avg_daily_volume', 0),
                'avg_daily_value_rub': row.get('avg_daily_value_rub', 0),
                'current_price': row.get('current_price', 0),
                'last_price': row.get('last_price', 0),
                'annual_return': row.get('annual_return', 0),
                'volatility': row.get('volatility', 0),
                'sharpe_ratio': row.get('sharpe_ratio', 0),
                'has_detailed_info': fund_info['category'] != '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
            })
        
        return pd.DataFrame(detailed_info)
    
    def analyze_composition_flows(self) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Ç–æ–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–æ–≤ —Ñ–æ–Ω–¥–æ–≤"""
        
        detailed_funds = self.get_detailed_fund_info()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_flows = detailed_funds.groupby('category').agg({
            'avg_daily_volume': 'sum',
            'annual_return': 'mean',
            'volatility': 'mean',
            'ticker': 'count'
        }).round(2)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –ø–æ —Å—Ç–∏–ª—è–º –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        style_flows = detailed_funds.groupby('investment_style').agg({
            'avg_daily_volume': 'sum',
            'annual_return': 'mean',
            'ticker': 'count'
        }).round(2)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –ø–æ —É—Ä–æ–≤–Ω—é —Ä–∏—Å–∫–∞
        risk_flows = detailed_funds.groupby('risk_level').agg({
            'avg_daily_volume': 'sum',
            'annual_return': 'mean',
            'ticker': 'count'
        }).round(2)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏
        total_funds = len(detailed_funds)
        detailed_funds_count = len(detailed_funds[detailed_funds['has_detailed_info']])
        coverage = (detailed_funds_count / total_funds * 100) if total_funds > 0 else 0
        
        return {
            'category_flows': category_flows.to_dict('index'),
            'style_flows': style_flows.to_dict('index'),
            'risk_flows': risk_flows.to_dict('index'),
            'coverage_stats': {
                'total_funds': total_funds,
                'detailed_funds': detailed_funds_count,
                'coverage_percent': round(coverage, 1)
            },
            'analysis_timestamp': datetime.now().isoformat()
        }

def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ ETF
    try:
        data_files = list(Path('.').glob('enhanced_etf_data_*.csv'))
        if not data_files:
            data_files = list(Path('.').glob('full_moex_etf_data_*.csv'))
            
        if not data_files:
            print("‚ùå –§–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ ETF –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
            
        latest_data = max(data_files, key=lambda x: x.stat().st_mtime)
        print(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {latest_data}")
        
        etf_data = pd.read_csv(latest_data)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(etf_data)} ETF")
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = CapitalFlowAnalyzer(etf_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –∫–∞–ø–∏—Ç–∞–ª–∞
        print("\nüîÑ –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞...")
        
        sector_flows = analyzer.calculate_sector_flows()
        print(f"\nüìà –ü–æ—Ç–æ–∫–∏ –∫–∞–ø–∏—Ç–∞–ª–∞ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º:")
        print(sector_flows[['volume_share', 'market_cap_share', 'avg_return', 'etf_count']])
        
        sentiment = analyzer.detect_risk_sentiment()
        print(f"\nüéØ –†—ã–Ω–æ—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è: {sentiment['sentiment']} ({sentiment['confidence']}%)")
        print(f"   –ó–∞—â–∏—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã: {sentiment['defensive_share']}%")
        print(f"   –†–∏—Å–∫–æ–≤—ã–µ –∞–∫—Ç–∏–≤—ã: {sentiment['risky_share']}%")
        
        momentum = analyzer.analyze_sector_momentum()
        print(f"\n‚ö° –¢–æ–ø-3 —Å–µ–∫—Ç–æ—Ä–∞ –ø–æ –º–æ–º–µ–Ω—Ç—É–º—É:")
        for sector in momentum.head(3).index:
            data = momentum.loc[sector]
            print(f"   {sector}: {data['momentum_score']} ({data['momentum_trend']})")
            
        anomalies = analyzer.detect_flow_anomalies()
        if anomalies:
            print(f"\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π:")
            for anomaly in anomalies[:3]:
                print(f"   {anomaly['type']} –≤ —Å–µ–∫—Ç–æ—Ä–µ {anomaly['sector']}: {anomaly['value']} ({anomaly['severity']})")
        
        insights = analyzer.generate_flow_insights()
        print(f"\nüí° –û–±—â–∏–µ –∏–Ω—Å–∞–π—Ç—ã:")
        print(f"   –õ–∏–¥–µ—Ä—ã –ø–æ –æ–±—ä–µ–º—É: {', '.join(insights['top_volume_sectors'])}")
        print(f"   –õ–∏–¥–µ—Ä—ã –ø–æ –º–æ–º–µ–Ω—Ç—É–º—É: {', '.join(insights['momentum_leaders'])}")
        print(f"   –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∞–Ω–æ–º–∞–ª–∏–π: {insights['critical_anomalies']}")
        
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")

if __name__ == "__main__":
    main()