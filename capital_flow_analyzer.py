#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞ –∏ —Ç—Ä–µ–Ω–¥–æ–≤ –¥–ª—è —Ä—ã–Ω–∫–∞ –ë–ü–ò–§
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –¥–≤–∏–∂–µ–Ω–∏–µ –¥–µ–Ω–µ–≥ –º–µ–∂–¥—É —Å–µ–∫—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import json
from pathlib import Path
from full_fund_compositions import get_fund_category, FUND_COMPOSITIONS
from historical_data_manager import HistoricalDataManager

class CapitalFlowAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞ –º–µ–∂–¥—É —Å–µ–∫—Ç–æ—Ä–∞–º–∏ ETF"""
    
    def __init__(self, etf_data: pd.DataFrame, historical_manager: Optional[HistoricalDataManager] = None):
        self.etf_data = etf_data
        self.historical_manager = historical_manager or HistoricalDataManager()
        self.asset_type_mapping = self._create_asset_type_mapping()
        
    def _create_asset_type_mapping(self) -> Dict[str, str]:
        """–°–æ–∑–¥–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ ETF –ø–æ —Ç–∏–ø–∞–º –∞–∫—Ç–∏–≤–æ–≤ (–∫–∞–∫ –≤ —Å–µ–∫—Ç–æ—Ä–∞–ª—å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ)"""
        asset_type_map = {}
        
        def group_by_asset_type(sector, ticker='', name=''):
            sector_lower = sector.lower()
            name_lower = name.lower() if name else ''
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–ª—é—Ç–Ω—ã—Ö —Ñ–æ–Ω–¥–æ–≤
            if '–≤–∞–ª—é—Ç–Ω' in sector_lower or '–≤–∞–ª—é—Ç' in sector_lower:
                if '–æ–±–ª–∏–≥–∞—Ü–∏–∏' in name_lower or '–æ–±–ª–∏–≥–∞—Ü' in name_lower:
                    return '–û–±–ª–∏–≥–∞—Ü–∏–∏'
                elif ('–ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å' in name_lower or '–Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π' in name_lower or 
                      '—Å–±–µ—Ä–µ–≥–∞—Ç–µ–ª—å–Ω—ã–π' in name_lower):
                    return '–î–µ–Ω–µ–∂–Ω—ã–π —Ä—ã–Ω–æ–∫'
                else:
                    return '–°–º–µ—à–∞–Ω–Ω—ã–µ'
            
            # –ê–Ω—Ç–∏–∏–Ω—Ñ–ª—è—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–æ–Ω–¥—ã –æ—Ç–Ω–æ—Å–∏–º –∫ —Å–º–µ—à–∞–Ω–Ω—ã–º
            elif '–∑–∞—â–∏—Ç–Ω' in sector_lower or '–∞–Ω—Ç–∏–∏–Ω—Ñ–ª—è—Ü' in sector_lower:
                return '–°–º–µ—à–∞–Ω–Ω—ã–µ'
            
            # –î—Ä–∞–≥–æ—Ü–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–ª–ª—ã –æ—Å—Ç–∞—é—Ç—Å—è —Ç–æ–≤–∞—Ä–∞–º–∏
            elif '–∑–æ–ª–æ—Ç' in sector_lower or '–¥—Ä–∞–≥–æ—Ü–µ–Ω–Ω' in sector_lower or '–º–µ—Ç–∞–ª–ª' in sector_lower:
                return '–¢–æ–≤–∞—Ä—ã'
            
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            elif '–∞–∫—Ü–∏' in sector_lower:
                return '–ê–∫—Ü–∏–∏'
            elif '–æ–±–ª–∏–≥–∞' in sector_lower:
                return '–û–±–ª–∏–≥–∞—Ü–∏–∏'
            elif '–¥–µ–Ω–µ–∂–Ω' in sector_lower or '–ª–∏–∫–≤–∏–¥–Ω' in sector_lower:
                return '–î–µ–Ω–µ–∂–Ω—ã–π —Ä—ã–Ω–æ–∫'
            elif '—Å–º–µ—à–∞–Ω–Ω' in sector_lower or '–¥–∏–≤–µ—Ä—Å' in sector_lower:
                return '–°–º–µ—à–∞–Ω–Ω—ã–µ'
            else:
                return '–ü—Ä–æ—á–∏–µ'
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É –∫ –∫–∞–∂–¥–æ–º—É ETF
        for _, row in self.etf_data.iterrows():
            ticker = row['ticker']
            sector = row.get('sector', '')
            name = row.get('name', '')
            
            asset_type_map[ticker] = group_by_asset_type(sector, ticker, name)
                
        return asset_type_map
    
    def calculate_real_capital_flows(self, days: int = 30) -> pd.DataFrame:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏—Ç–æ–∫–∏/–æ—Ç—Ç–æ–∫–∏ –∫–∞–ø–∏—Ç–∞–ª–∞ —á–µ—Ä–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –°–ß–ê"""
        
        flows_data = []
        
        for _, row in self.etf_data.iterrows():
            ticker = row['ticker']
            current_nav = row.get('market_cap', 0)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø –∞–∫—Ç–∏–≤–æ–≤
            asset_type = self.asset_type_mapping.get(ticker, '–ü—Ä–æ—á–∏–µ')
            
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –°–ß–ê
                if hasattr(self.historical_manager, 'get_nav_history'):
                    nav_history = self.historical_manager.get_nav_history(ticker, days=days)
                else:
                    nav_history = None
                
                if nav_history is not None and len(nav_history) >= 2:
                    # –ï—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ - —Å—á–∏—Ç–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫
                    nav_start = nav_history.iloc[0].get('nav', current_nav)
                    nav_end = nav_history.iloc[-1].get('nav', current_nav)
                    
                    # –ò—Å–∫–ª—é—á–∞–µ–º –≤–ª–∏—è–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã –ø–∞—è (—Ä—ã–Ω–æ—á–Ω—ã–π —Ä–æ—Å—Ç/–ø–∞–¥–µ–Ω–∏–µ)
                    price_start = nav_history.iloc[0].get('price', 100)
                    price_end = nav_history.iloc[-1].get('price', 100)
                    
                    if price_start > 0:
                        market_growth = (price_end / price_start - 1)
                        expected_nav = nav_start * (1 + market_growth)
                        
                        # –†–µ–∞–ª—å–Ω—ã–π –ø—Ä–∏—Ç–æ–∫/–æ—Ç—Ç–æ–∫ = —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –∏ –æ–∂–∏–¥–∞–µ–º—ã–º –°–ß–ê
                        net_flow = nav_end - expected_nav
                        flow_percent = (net_flow / nav_start) * 100 if nav_start > 0 else 0
                    else:
                        net_flow = nav_end - nav_start
                        flow_percent = (net_flow / nav_start) * 100 if nav_start > 0 else 0
                        
                else:
                    # –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
                    annual_return = row.get('annual_return', 0)
                    period_return = annual_return * (days / 365)
                    
                    # –ï—Å–ª–∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç —Å—Ä–µ–¥–Ω–µ—Ä—ã–Ω–æ—á–Ω–æ–π, 
                    # —ç—Ç–æ –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø—Ä–∏—Ç–æ–∫–∏/–æ—Ç—Ç–æ–∫–∏
                    market_avg_return = self.etf_data['annual_return'].mean()
                    period_market_return = market_avg_return * (days / 365)
                    
                    excess_return = period_return - period_market_return
                    
                    # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞: –∏–∑–±—ã—Ç–æ—á–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø–æ—Ç–æ–∫–∏
                    flow_percent = excess_return * 0.3  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø–æ—Ç–æ–∫–æ–≤ –∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
                    net_flow = (flow_percent / 100) * current_nav if current_nav > 0 else 0
                
            except Exception as e:
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                net_flow = 0
                flow_percent = 0
            
            flows_data.append({
                'ticker': ticker,
                'asset_type': asset_type,
                'nav_current': current_nav,
                'net_flow_rub': net_flow,
                'flow_percent': round(flow_percent, 2),
                'flow_direction': '–ü—Ä–∏—Ç–æ–∫' if net_flow > 0 else ('–û—Ç—Ç–æ–∫' if net_flow < 0 else '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ'),
                'flow_intensity': abs(flow_percent)
            })
        
        flows_df = pd.DataFrame(flows_data)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –∞–∫—Ç–∏–≤–æ–≤
        asset_flows = flows_df.groupby('asset_type').agg({
            'nav_current': 'sum',
            'net_flow_rub': 'sum',
            'flow_percent': 'mean',
            'flow_intensity': 'mean',
            'ticker': 'count'
        }).round(2)
        
        asset_flows.columns = [
            'total_nav', 'total_net_flow', 'avg_flow_percent', 
            'avg_flow_intensity', 'funds_count'
        ]
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–æ–ª—é –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∞–∫—Ç–∏–≤–æ–≤
        total_nav = asset_flows['total_nav'].sum()
        if total_nav > 0:
            asset_flows['nav_share'] = (asset_flows['total_nav'] / total_nav * 100).round(1)
            asset_flows['flow_share'] = (asset_flows['total_net_flow'] / asset_flows['total_net_flow'].abs().sum() * 100).round(1)
        else:
            asset_flows['nav_share'] = 0
            asset_flows['flow_share'] = 0
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∞–∫—Ç–∏–≤–æ–≤
        asset_flows['flow_direction'] = asset_flows['total_net_flow'].apply(
            lambda x: '–ü—Ä–∏—Ç–æ–∫' if x > 0 else ('–û—Ç—Ç–æ–∫' if x < 0 else '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ')
        )
        
        return asset_flows.sort_values('total_net_flow', ascending=False)
    
    def detect_risk_sentiment(self) -> Dict[str, any]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (risk-on/risk-off) –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞"""
        
        asset_flows = self.calculate_real_capital_flows()
        
        # –ó–∞—â–∏—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã (risk-off)
        defensive_assets = ['–û–±–ª–∏–≥–∞—Ü–∏–∏', '–î–µ–Ω–µ–∂–Ω—ã–π —Ä—ã–Ω–æ–∫', '–¢–æ–≤–∞—Ä—ã']  # –¢–æ–≤–∞—Ä—ã –≤–∫–ª—é—á–∞—é—Ç –∑–æ–ª–æ—Ç–æ
        # –†–∏—Å–∫–æ–≤—ã–µ –∞–∫—Ç–∏–≤—ã (risk-on) 
        risky_assets = ['–ê–∫—Ü–∏–∏']
        
        defensive_flow = asset_flows[
            asset_flows.index.isin(defensive_assets)
        ]['total_net_flow'].sum()
        
        risky_flow = asset_flows[
            asset_flows.index.isin(risky_assets)
        ]['total_net_flow'].sum()
        
        # –¢–∞–∫–∂–µ —É—á–∏—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–º—ã (–°–ß–ê)
        defensive_nav = asset_flows[
            asset_flows.index.isin(defensive_assets)
        ]['nav_share'].sum()
        
        risky_nav = asset_flows[
            asset_flows.index.isin(risky_assets)
        ]['nav_share'].sum()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤
        if defensive_flow > abs(risky_flow) * 0.5 and defensive_flow > 0:
            sentiment = "Risk-Off"
            confidence = min(95, abs(defensive_flow) / max(abs(risky_flow), 1) * 40)
        elif risky_flow > abs(defensive_flow) * 0.5 and risky_flow > 0:
            sentiment = "Risk-On" 
            confidence = min(95, abs(risky_flow) / max(abs(defensive_flow), 1) * 40)
        else:
            sentiment = "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π"
            confidence = 30
        
        return {
            'sentiment': sentiment,
            'confidence': round(confidence, 1),
            'defensive_flow': round(defensive_flow / 1e9, 2),  # –≤ –º–ª—Ä–¥ —Ä—É–±
            'risky_flow': round(risky_flow / 1e9, 2),         # –≤ –º–ª—Ä–¥ —Ä—É–±
            'defensive_share': round(defensive_nav, 1),
            'risky_share': round(risky_nav, 1)
        }
    
    def analyze_sector_momentum(self) -> pd.DataFrame:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–º–µ–Ω—Ç—É–º –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        
        sector_flows = self.calculate_sector_flows()
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –º–æ–º–µ–Ω—Ç—É–º–∞
        sector_flows['momentum_score'] = (
            sector_flows['avg_return'] * 0.4 +  # –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
            (100 - sector_flows['avg_volatility']) * 0.3 +  # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
            sector_flows['volume_share'] * 0.3  # –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤
        ).round(1)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –º–æ–º–µ–Ω—Ç—É–º
        def classify_momentum(score):
            if score >= 70:
                return "–°–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç"
            elif score >= 50:
                return "–£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç"
            elif score >= 30:
                return "–°—Ç–∞–≥–Ω–∞—Ü–∏—è"
            else:
                return "–°–Ω–∏–∂–µ–Ω–∏–µ"
                
        sector_flows['momentum_trend'] = sector_flows['momentum_score'].apply(classify_momentum)
        
        return sector_flows.sort_values('momentum_score', ascending=False)
    
    def detect_flow_anomalies(self) -> List[Dict]:
        """–í—ã—è–≤–ª—è–µ—Ç –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø–æ—Ç–æ–∫–∏ –∫–∞–ø–∏—Ç–∞–ª–∞"""
        
        sector_flows = self.calculate_sector_flows()
        anomalies = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–æ–º–∞–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–µ –æ–±—ä–µ–º—ã
        volume_threshold = sector_flows['volume_share'].mean() + 2 * sector_flows['volume_share'].std()
        
        for sector, data in sector_flows.iterrows():
            if data['volume_share'] > volume_threshold:
                anomalies.append({
                    'type': '–í—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º',
                    'sector': sector,
                    'value': data['volume_share'],
                    'threshold': round(volume_threshold, 1),
                    'severity': '–í—ã—Å–æ–∫–∞—è' if data['volume_share'] > volume_threshold * 1.5 else '–°—Ä–µ–¥–Ω—è—è'
                })
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–æ–º–∞–ª—å–Ω—É—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        return_threshold = abs(sector_flows['avg_return'].mean()) + 2 * sector_flows['avg_return'].std()
        
        for sector, data in sector_flows.iterrows():
            if abs(data['avg_return']) > return_threshold:
                anomalies.append({
                    'type': '–ê–Ω–æ–º–∞–ª—å–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å',
                    'sector': sector, 
                    'value': data['avg_return'],
                    'threshold': round(return_threshold, 1),
                    'severity': '–í—ã—Å–æ–∫–∞—è' if abs(data['avg_return']) > return_threshold * 1.5 else '–°—Ä–µ–¥–Ω—è—è'
                })
                
        return sorted(anomalies, key=lambda x: x['value'], reverse=True)
    
    def generate_flow_insights(self) -> Dict[str, any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Å–∞–π—Ç—ã –ø–æ –ø–æ—Ç–æ–∫–∞–º –∫–∞–ø–∏—Ç–∞–ª–∞"""
        
        sector_flows = self.calculate_sector_flows()
        sentiment = self.detect_risk_sentiment()
        momentum = self.analyze_sector_momentum()
        anomalies = self.detect_flow_anomalies()
        
        # –¢–æ–ø —Å–µ–∫—Ç–æ—Ä—ã –ø–æ –æ–±—ä–µ–º—É
        top_sectors = sector_flows.head(3).index.tolist()
        
        # –°–µ–∫—Ç–æ—Ä—ã —Å –ª—É—á—à–∏–º –º–æ–º–µ–Ω—Ç—É–º–æ–º
        momentum_leaders = momentum.head(3).index.tolist()
        
        insights = {
            'market_sentiment': sentiment,
            'top_volume_sectors': top_sectors,
            'momentum_leaders': momentum_leaders,
            'total_anomalies': len(anomalies),
            'critical_anomalies': len([a for a in anomalies if a['severity'] == '–í—ã—Å–æ–∫–∞—è']),
            'sector_count': len(sector_flows),
            'analysis_timestamp': datetime.now().isoformat()
        }
        
        return insights
    
    def analyze_fund_flows(self) -> pd.DataFrame:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Ç–æ–∫–∏ –º–µ–∂–¥—É –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ñ–æ–Ω–¥–∞–º–∏"""
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–æ–Ω–¥–∞—Ö
        fund_flows = self.etf_data.copy()
        fund_flows['sector'] = fund_flows['ticker'].map(
            lambda x: self.sector_mapping.get(x, '–°–º–µ—à–∞–Ω–Ω—ã–µ/–ü—Ä–æ—á–∏–µ')
        )
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–Ω–¥–∞
        fund_flows['flow_score'] = (
            fund_flows['avg_daily_volume'] / fund_flows['avg_daily_volume'].max() * 50 +
            abs(fund_flows['annual_return']) / abs(fund_flows['annual_return']).max() * 30 +
            (100 - fund_flows['volatility']) / 100 * 20
        ).round(1)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–∞ (–ø—Ä–∏—Ç–æ–∫/–æ—Ç—Ç–æ–∫)
        fund_flows['flow_direction'] = fund_flows.apply(lambda row: 
            '–ü—Ä–∏—Ç–æ–∫' if row['annual_return'] > 0 and row['avg_daily_volume'] > fund_flows['avg_daily_volume'].median()
            else '–û—Ç—Ç–æ–∫' if row['annual_return'] < 0 and row['avg_daily_volume'] > fund_flows['avg_daily_volume'].median()
            else '–°—Ç–∞–±–∏–ª—å–Ω—ã–π', axis=1
        )
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—ä–µ–º—É —Ç–æ—Ä–≥–æ–≤
        fund_flows = fund_flows.sort_values('avg_daily_volume', ascending=False)
        
        return fund_flows[['ticker', 'full_name', 'sector', 'avg_daily_volume', 
                          'annual_return', 'volatility', 'flow_score', 'flow_direction']]
    
    def detect_sector_rotation(self) -> Dict[str, any]:
        """–í—ã—è–≤–ª—è–µ—Ç —Ä–æ—Ç–∞—Ü–∏—é –º–µ–∂–¥—É —Å–µ–∫—Ç–æ—Ä–∞–º–∏"""
        
        sector_flows = self.calculate_sector_flows()
        fund_flows = self.analyze_fund_flows()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º
        inflow_sectors = []
        outflow_sectors = []
        
        for sector in sector_flows.index:
            sector_funds = fund_flows[fund_flows['sector'] == sector]
            
            if len(sector_funds) > 0:
                inflow_count = len(sector_funds[sector_funds['flow_direction'] == '–ü—Ä–∏—Ç–æ–∫'])
                outflow_count = len(sector_funds[sector_funds['flow_direction'] == '–û—Ç—Ç–æ–∫'])
                total_volume = sector_funds['avg_daily_volume'].sum()
                
                if inflow_count > outflow_count and total_volume > 0:
                    inflow_sectors.append({
                        'sector': sector,
                        'net_flow': inflow_count - outflow_count,
                        'volume': total_volume,
                        'funds_count': len(sector_funds)
                    })
                elif outflow_count > inflow_count:
                    outflow_sectors.append({
                        'sector': sector,
                        'net_flow': outflow_count - inflow_count,
                        'volume': total_volume,
                        'funds_count': len(sector_funds)
                    })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∏–ª–µ –ø–æ—Ç–æ–∫–∞
        inflow_sectors = sorted(inflow_sectors, key=lambda x: x['net_flow'], reverse=True)
        outflow_sectors = sorted(outflow_sectors, key=lambda x: x['net_flow'], reverse=True)
        
        return {
            'inflow_sectors': inflow_sectors[:5],  # –¢–æ–ø-5 —Å–µ–∫—Ç–æ—Ä–æ–≤ —Å –ø—Ä–∏—Ç–æ–∫–æ–º
            'outflow_sectors': outflow_sectors[:5],  # –¢–æ–ø-5 —Å–µ–∫—Ç–æ—Ä–æ–≤ —Å –æ—Ç—Ç–æ–∫–æ–º
            'rotation_strength': len(inflow_sectors) + len(outflow_sectors),
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def get_detailed_fund_info(self) -> pd.DataFrame:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–∞–≤–∞—Ö —Ñ–æ–Ω–¥–æ–≤"""
        
        detailed_info = []
        
        for _, row in self.etf_data.iterrows():
            ticker = row['ticker']
            isin = row.get('isin', '')
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            fund_info = get_fund_category(isin)
            
            detailed_info.append({
                'ticker': ticker,
                'isin': isin,
                'full_name': row.get('full_name', ''),
                'category': fund_info['category'],
                'subcategory': fund_info['subcategory'],
                'risk_level': fund_info['risk_level'],
                'investment_style': fund_info['investment_style'],
                'avg_daily_volume': row.get('avg_daily_volume', 0),
                'avg_daily_value_rub': row.get('avg_daily_value_rub', 0),
                'current_price': row.get('current_price', 0),
                'last_price': row.get('last_price', 0),
                'annual_return': row.get('annual_return', 0),
                'volatility': row.get('volatility', 0),
                'sharpe_ratio': row.get('sharpe_ratio', 0),
                'has_detailed_info': fund_info['category'] != '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
            })
        
        return pd.DataFrame(detailed_info)
    
    def analyze_composition_flows(self) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Ç–æ–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–æ–≤ —Ñ–æ–Ω–¥–æ–≤"""
        
        detailed_funds = self.get_detailed_fund_info()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_flows = detailed_funds.groupby('category').agg({
            'avg_daily_volume': 'sum',
            'annual_return': 'mean',
            'volatility': 'mean',
            'ticker': 'count'
        }).round(2)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –ø–æ —Å—Ç–∏–ª—è–º –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        style_flows = detailed_funds.groupby('investment_style').agg({
            'avg_daily_volume': 'sum',
            'annual_return': 'mean',
            'ticker': 'count'
        }).round(2)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –ø–æ —É—Ä–æ–≤–Ω—é —Ä–∏—Å–∫–∞
        risk_flows = detailed_funds.groupby('risk_level').agg({
            'avg_daily_volume': 'sum',
            'annual_return': 'mean',
            'ticker': 'count'
        }).round(2)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏
        total_funds = len(detailed_funds)
        detailed_funds_count = len(detailed_funds[detailed_funds['has_detailed_info']])
        coverage = (detailed_funds_count / total_funds * 100) if total_funds > 0 else 0
        
        return {
            'category_flows': category_flows.to_dict('index'),
            'style_flows': style_flows.to_dict('index'),
            'risk_flows': risk_flows.to_dict('index'),
            'coverage_stats': {
                'total_funds': total_funds,
                'detailed_funds': detailed_funds_count,
                'coverage_percent': round(coverage, 1)
            },
            'analysis_timestamp': datetime.now().isoformat()
        }

def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ ETF
    try:
        data_files = list(Path('.').glob('enhanced_etf_data_*.csv'))
        if not data_files:
            data_files = list(Path('.').glob('full_moex_etf_data_*.csv'))
            
        if not data_files:
            print("‚ùå –§–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ ETF –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
            
        latest_data = max(data_files, key=lambda x: x.stat().st_mtime)
        print(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {latest_data}")
        
        etf_data = pd.read_csv(latest_data)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(etf_data)} ETF")
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = CapitalFlowAnalyzer(etf_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –∫–∞–ø–∏—Ç–∞–ª–∞
        print("\nüîÑ –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞...")
        
        sector_flows = analyzer.calculate_sector_flows()
        print(f"\nüìà –ü–æ—Ç–æ–∫–∏ –∫–∞–ø–∏—Ç–∞–ª–∞ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º:")
        print(sector_flows[['volume_share', 'market_cap_share', 'avg_return', 'etf_count']])
        
        sentiment = analyzer.detect_risk_sentiment()
        print(f"\nüéØ –†—ã–Ω–æ—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è: {sentiment['sentiment']} ({sentiment['confidence']}%)")
        print(f"   –ó–∞—â–∏—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã: {sentiment['defensive_share']}%")
        print(f"   –†–∏—Å–∫–æ–≤—ã–µ –∞–∫—Ç–∏–≤—ã: {sentiment['risky_share']}%")
        
        momentum = analyzer.analyze_sector_momentum()
        print(f"\n‚ö° –¢–æ–ø-3 —Å–µ–∫—Ç–æ—Ä–∞ –ø–æ –º–æ–º–µ–Ω—Ç—É–º—É:")
        for sector in momentum.head(3).index:
            data = momentum.loc[sector]
            print(f"   {sector}: {data['momentum_score']} ({data['momentum_trend']})")
            
        anomalies = analyzer.detect_flow_anomalies()
        if anomalies:
            print(f"\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π:")
            for anomaly in anomalies[:3]:
                print(f"   {anomaly['type']} –≤ —Å–µ–∫—Ç–æ—Ä–µ {anomaly['sector']}: {anomaly['value']} ({anomaly['severity']})")
        
        insights = analyzer.generate_flow_insights()
        print(f"\nüí° –û–±—â–∏–µ –∏–Ω—Å–∞–π—Ç—ã:")
        print(f"   –õ–∏–¥–µ—Ä—ã –ø–æ –æ–±—ä–µ–º—É: {', '.join(insights['top_volume_sectors'])}")
        print(f"   –õ–∏–¥–µ—Ä—ã –ø–æ –º–æ–º–µ–Ω—Ç—É–º—É: {', '.join(insights['momentum_leaders'])}")
        print(f"   –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∞–Ω–æ–º–∞–ª–∏–π: {insights['critical_anomalies']}")
        
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ç–æ–∫–æ–≤ –∫–∞–ø–∏—Ç–∞–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")

if __name__ == "__main__":
    main()