#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –°–ß–ê (–°—Ç–æ–∏–º–æ—Å—Ç–∏ –ß–∏—Å—Ç—ã—Ö –ê–∫—Ç–∏–≤–æ–≤) –ë–ü–ò–§
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã —Ñ–æ–Ω–¥–æ–≤, –∏—Ö —Ä–æ—Å—Ç/—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –∏ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é —Ä—ã–Ω–∫–∞
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import requests
import json
from pathlib import Path
import logging
from dataclasses import dataclass

@dataclass
class NAVAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –°–ß–ê"""
    total_market_size: float
    largest_funds: List[Dict[str, any]]
    market_concentration: Dict[str, float]
    size_distribution: Dict[str, int]
    growth_leaders: List[Dict[str, any]]
    declining_funds: List[Dict[str, any]]

class NAVAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –°–ß–ê (—Å—Ç–æ–∏–º–æ—Å—Ç–∏ —á–∏—Å—Ç—ã—Ö –∞–∫—Ç–∏–≤–æ–≤) –ë–ü–ò–§"""
    
    def __init__(self):
        self.logger = self._setup_logger()
        self._cache = {}
        
    def _setup_logger(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞"""
        logger = logging.getLogger('NAVAnalyzer')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
    
    def get_fund_nav_from_moex(self, ticker: str) -> Dict[str, any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –°–ß–ê —Ñ–æ–Ω–¥–∞ –∏–∑ MOEX API
        
        Args:
            ticker: –¢–∏–∫–µ—Ä —Ñ–æ–Ω–¥–∞
            
        Returns:
            –î–∞–Ω–Ω—ã–µ –æ –°–ß–ê –∏ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏
        """
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–æ–Ω–¥–µ
            url = f"https://iss.moex.com/iss/engines/stock/markets/shares/securities/{ticker}.json"
            
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                nav_info = {}
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ marketdata
                if 'marketdata' in data and 'data' in data['marketdata']:
                    columns = data['marketdata']['columns']
                    market_data = data['marketdata']['data']
                    
                    if market_data:
                        row = market_data[0]
                        market_info = dict(zip(columns, row))
                        
                        nav_info.update({
                            'last_price': market_info.get('LAST', 0),
                            'market_cap': market_info.get('MARKETPRICE', 0),
                            'volume': market_info.get('VOLTODAY', 0),
                            'value': market_info.get('VALTODAY', 0),
                            'change': market_info.get('CHANGE', 0),
                            'change_percent': market_info.get('PRCCHANGE', 0),
                        })
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ securities
                if 'securities' in data and 'data' in data['securities']:
                    columns = data['securities']['columns']
                    securities_data = data['securities']['data']
                    
                    if securities_data:
                        row = securities_data[0]
                        security_info = dict(zip(columns, row))
                        
                        nav_info.update({
                            'full_name': security_info.get('SECNAME', ''),
                            'short_name': security_info.get('SHORTNAME', ''),
                            'isin': security_info.get('ISIN', ''),
                            'lot_size': security_info.get('LOTSIZE', 1),
                            'face_value': security_info.get('FACEVALUE', 0),
                            'issue_size': security_info.get('ISSUESIZE', 0),
                        })
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—É—é –°–ß–ê
                if nav_info.get('last_price') and nav_info.get('issue_size'):
                    estimated_nav = nav_info['last_price'] * nav_info['issue_size']
                    nav_info['estimated_nav'] = estimated_nav
                
                return nav_info
            else:
                self.logger.warning(f"MOEX API error for {ticker}: HTTP {response.status_code}")
                return {}
                
        except Exception as e:
            self.logger.error(f"Error getting NAV data for {ticker}: {e}")
            return {}
    
    def analyze_fund_sizes(self, etf_data: pd.DataFrame) -> NAVAnalysisResult:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä—ã —Ñ–æ–Ω–¥–æ–≤ –∏ –∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        
        Args:
            etf_data: –î–∞–Ω–Ω—ã–µ –æ —Ñ–æ–Ω–¥–∞—Ö
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –°–ß–ê
        """
        self.logger.info("–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ñ–æ–Ω–¥–æ–≤...")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        funds_with_size = []
        
        for _, fund in etf_data.iterrows():
            ticker = fund['ticker']
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º market_cap –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º
            market_cap = fund.get('market_cap', 0)
            
            # –ï—Å–ª–∏ market_cap –Ω–µ—Ç –∏–ª–∏ —Ä–∞–≤–µ–Ω 0, –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å
            if not market_cap or market_cap == 0:
                last_price = fund.get('last_price', fund.get('current_price', 0))
                avg_volume = fund.get('avg_daily_volume', 0)
                
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±–æ—Ä–æ—Ç–æ–≤
                if last_price and avg_volume:
                    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –¥–Ω–µ–≤–Ω–æ–π –æ–±–æ—Ä–æ—Ç —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 1-2% –æ—Ç –°–ß–ê
                    estimated_nav = (avg_volume * last_price) * 50  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                    market_cap = estimated_nav
            
            fund_info = {
                'ticker': ticker,
                'name': fund.get('full_name', fund.get('short_name', ticker)),
                'market_cap': market_cap,
                'last_price': fund.get('last_price', fund.get('current_price', 0)),
                'volume': fund.get('avg_daily_volume', 0),
                'annual_return': fund.get('annual_return', 0),
                'volatility': fund.get('volatility', 0),
                'inception_date': fund.get('inception_date', ''),
                'category': fund.get('category', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            }
            
            funds_with_size.append(fund_info)
        
        funds_df = pd.DataFrame(funds_with_size)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ñ–æ–Ω–¥—ã —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –æ —Ä–∞–∑–º–µ—Ä–µ
        valid_funds = funds_df[funds_df['market_cap'] > 0].copy()
        
        if valid_funds.empty:
            self.logger.warning("–ù–µ—Ç —Ñ–æ–Ω–¥–æ–≤ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –æ —Ä–∞–∑–º–µ—Ä–µ")
            return NAVAnalysisResult(
                total_market_size=0,
                largest_funds=[],
                market_concentration={},
                size_distribution={},
                growth_leaders=[],
                declining_funds=[]
            )
        
        # –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞
        total_market_size = valid_funds['market_cap'].sum()
        
        # –ö—Ä—É–ø–Ω–µ–π—à–∏–µ —Ñ–æ–Ω–¥—ã
        largest_funds = valid_funds.nlargest(20, 'market_cap').to_dict('records')
        
        # –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è —Ä—ã–Ω–∫–∞
        market_concentration = self._calculate_market_concentration(valid_funds)
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
        size_distribution = self._categorize_by_size(valid_funds)
        
        # –õ–∏–¥–µ—Ä—ã —Ä–æ—Å—Ç–∞ –∏ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è (–Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∫–∞–∫ –ø—Ä–æ–∫—Å–∏)
        growth_leaders = valid_funds.nlargest(10, 'annual_return').to_dict('records')
        declining_funds = valid_funds.nsmallest(10, 'annual_return').to_dict('records')
        
        return NAVAnalysisResult(
            total_market_size=total_market_size,
            largest_funds=largest_funds,
            market_concentration=market_concentration,
            size_distribution=size_distribution,
            growth_leaders=growth_leaders,
            declining_funds=declining_funds
        )
    
    def _calculate_market_concentration(self, funds_df: pd.DataFrame) -> Dict[str, float]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏ —Ä—ã–Ω–∫–∞"""
        
        total_cap = funds_df['market_cap'].sum()
        funds_sorted = funds_df.sort_values('market_cap', ascending=False)
        
        # –î–æ–ª–∏ –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö —Ñ–æ–Ω–¥–æ–≤
        top_5_share = funds_sorted.head(5)['market_cap'].sum() / total_cap * 100
        top_10_share = funds_sorted.head(10)['market_cap'].sum() / total_cap * 100
        top_20_share = funds_sorted.head(20)['market_cap'].sum() / total_cap * 100
        
        # –ò–Ω–¥–µ–∫—Å –•–µ—Ä—Ñ–∏–Ω–¥–∞–ª—è-–•–∏—Ä—à–º–∞–Ω–∞
        market_shares = funds_df['market_cap'] / total_cap
        hhi = (market_shares ** 2).sum() * 10000  # –£–º–Ω–æ–∂–∞–µ–º –Ω–∞ 10000 –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏
        if hhi < 1000:
            concentration_level = "–ù–∏–∑–∫–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è"
        elif hhi < 1800:
            concentration_level = "–£–º–µ—Ä–µ–Ω–Ω–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è"
        else:
            concentration_level = "–í—ã—Å–æ–∫–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è"
        
        return {
            'top_5_share': round(top_5_share, 1),
            'top_10_share': round(top_10_share, 1),
            'top_20_share': round(top_20_share, 1),
            'hhi_index': round(hhi, 0),
            'concentration_level': concentration_level,
            'total_funds': len(funds_df)
        }
    
    def _categorize_by_size(self, funds_df: pd.DataFrame) -> Dict[str, int]:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç —Ñ–æ–Ω–¥—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä–æ–≥–∏ (–≤ —Ä—É–±–ª—è—Ö)
        mega_threshold = 10_000_000_000    # 10 –º–ª—Ä–¥
        large_threshold = 1_000_000_000    # 1 –º–ª—Ä–¥  
        medium_threshold = 100_000_000     # 100 –º–ª–Ω
        small_threshold = 10_000_000       # 10 –º–ª–Ω
        
        size_categories = {
            'mega_funds': len(funds_df[funds_df['market_cap'] >= mega_threshold]),
            'large_funds': len(funds_df[
                (funds_df['market_cap'] >= large_threshold) & 
                (funds_df['market_cap'] < mega_threshold)
            ]),
            'medium_funds': len(funds_df[
                (funds_df['market_cap'] >= medium_threshold) & 
                (funds_df['market_cap'] < large_threshold)
            ]),
            'small_funds': len(funds_df[
                (funds_df['market_cap'] >= small_threshold) & 
                (funds_df['market_cap'] < medium_threshold)
            ]),
            'micro_funds': len(funds_df[funds_df['market_cap'] < small_threshold]),
        }
        
        return size_categories
    
    def analyze_size_trends(self, current_data: pd.DataFrame, 
                           historical_periods: List[Tuple[datetime, datetime]]) -> Dict[str, any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ —Ñ–æ–Ω–¥–æ–≤
        
        Args:
            current_data: –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            historical_periods: –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            
        Returns:
            –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ —Ä–∞–∑–º–µ—Ä–æ–≤
        """
        self.logger.info("–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ñ–æ–Ω–¥–æ–≤...")
        
        # –¢–µ–∫—É—â–∏–π –∞–Ω–∞–ª–∏–∑
        current_analysis = self.analyze_fund_sizes(current_data)
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_analysis = self._analyze_by_categories(current_data)
        
        # –ê–Ω–∞–ª–∏–∑ –≤–æ–∑—Ä–∞—Å—Ç–∞ —Ñ–æ–Ω–¥–æ–≤
        age_analysis = self._analyze_by_age(current_data)
        
        return {
            'current_snapshot': {
                'total_market_size': current_analysis.total_market_size,
                'concentration': current_analysis.market_concentration,
                'size_distribution': current_analysis.size_distribution
            },
            'category_breakdown': category_analysis,
            'age_analysis': age_analysis,
            'largest_funds': current_analysis.largest_funds[:10],
            'fastest_growing': current_analysis.growth_leaders[:5],
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _analyze_by_categories(self, funds_df: pd.DataFrame) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Ñ–æ–Ω–¥–æ–≤"""
        
        category_stats = funds_df.groupby('category').agg({
            'market_cap': ['sum', 'mean', 'count'],
            'annual_return': 'mean',
            'volatility': 'mean'
        }).round(2)
        
        # –£–ø—Ä–æ—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–ª–æ–Ω–æ–∫
        category_stats.columns = ['total_cap', 'avg_cap', 'funds_count', 'avg_return', 'avg_volatility']
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ª—é —Ä—ã–Ω–∫–∞
        total_market = category_stats['total_cap'].sum()
        category_stats['market_share'] = (category_stats['total_cap'] / total_market * 100).round(1)
        
        return category_stats.to_dict('index')
    
    def _analyze_by_age(self, funds_df: pd.DataFrame) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É —Ñ–æ–Ω–¥–æ–≤"""
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Ñ–æ–Ω–¥–æ–≤
        current_date = datetime.now()
        
        funds_with_age = funds_df.copy()
        funds_with_age['inception_date'] = pd.to_datetime(funds_with_age['inception_date'], errors='coerce')
        funds_with_age = funds_with_age.dropna(subset=['inception_date'])
        
        if funds_with_age.empty:
            return {}
        
        funds_with_age['age_years'] = (
            current_date - funds_with_age['inception_date']
        ).dt.days / 365.25
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ–º –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É
        def categorize_age(age):
            if age < 1:
                return 'new_funds'  # –ù–æ–≤—ã–µ (–¥–æ –≥–æ–¥–∞)
            elif age < 3:
                return 'young_funds'  # –ú–æ–ª–æ–¥—ã–µ (1-3 –≥–æ–¥–∞)
            elif age < 5:
                return 'mature_funds'  # –ó—Ä–µ–ª—ã–µ (3-5 –ª–µ—Ç)
            else:
                return 'veteran_funds'  # –í–µ—Ç–µ—Ä–∞–Ω—ã (5+ –ª–µ—Ç)
        
        funds_with_age['age_category'] = funds_with_age['age_years'].apply(categorize_age)
        
        age_stats = funds_with_age.groupby('age_category').agg({
            'market_cap': ['sum', 'mean', 'count'],
            'annual_return': 'mean',
            'age_years': 'mean'
        }).round(2)
        
        age_stats.columns = ['total_cap', 'avg_cap', 'funds_count', 'avg_return', 'avg_age']
        
        return age_stats.to_dict('index')
    
    def generate_nav_insights(self, analysis_result: NAVAnalysisResult) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Å–∞–π—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –°–ß–ê"""
        
        insights = []
        
        # –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞
        total_size_bil = analysis_result.total_market_size / 1_000_000_000
        insights.append(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞ –ë–ü–ò–§: {total_size_bil:.1f} –º–ª—Ä–¥ —Ä—É–±.")
        
        # –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è
        concentration = analysis_result.market_concentration
        insights.append(f"–¢–æ–ø-5 —Ñ–æ–Ω–¥–æ–≤ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—Ç {concentration['top_5_share']}% —Ä—ã–Ω–∫–∞")
        insights.append(f"–£—Ä–æ–≤–µ–Ω—å –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏: {concentration['concentration_level']}")
        
        # –†–∞–∑–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        size_dist = analysis_result.size_distribution
        total_funds = sum(size_dist.values())
        
        if size_dist['mega_funds'] > 0:
            insights.append(f"–ú–µ–≥–∞-—Ñ–æ–Ω–¥–æ–≤ (>10 –º–ª—Ä–¥): {size_dist['mega_funds']}")
        
        insights.append(f"–ö—Ä—É–ø–Ω—ã—Ö —Ñ–æ–Ω–¥–æ–≤ (>1 –º–ª—Ä–¥): {size_dist['large_funds']}")
        insights.append(f"–°—Ä–µ–¥–Ω–∏—Ö —Ñ–æ–Ω–¥–æ–≤ (100–º–ª–Ω-1–º–ª—Ä–¥): {size_dist['medium_funds']}")
        
        # –ö—Ä—É–ø–Ω–µ–π—à–∏–π —Ñ–æ–Ω–¥
        if analysis_result.largest_funds:
            largest = analysis_result.largest_funds[0]
            largest_size_bil = largest['market_cap'] / 1_000_000_000
            insights.append(f"–ö—Ä—É–ø–Ω–µ–π—à–∏–π —Ñ–æ–Ω–¥: {largest['ticker']} ({largest_size_bil:.1f} –º–ª—Ä–¥ —Ä—É–±.)")
        
        return insights

def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –°–ß–ê"""
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ ETF
        data_files = list(Path('.').glob('enhanced_etf_data_*.csv'))
        if not data_files:
            data_files = list(Path('.').glob('full_moex_etf_data_*.csv'))
            
        if not data_files:
            print("‚ùå –§–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ ETF –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
            
        latest_data = max(data_files, key=lambda x: x.stat().st_mtime)
        print(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {latest_data}")
        
        etf_data = pd.read_csv(latest_data)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(etf_data)} ETF")
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = NAVAnalyzer()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–æ–Ω–¥–æ–≤
        print("\nüí∞ –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ñ–æ–Ω–¥–æ–≤ (–°–ß–ê)...")
        
        analysis_result = analyzer.analyze_fund_sizes(etf_data)
        
        # –í—ã–≤–æ–¥–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüìà –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞: {analysis_result.total_market_size / 1_000_000_000:.1f} –º–ª—Ä–¥ —Ä—É–±.")
        
        print(f"\nüè¢ –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è —Ä—ã–Ω–∫–∞:")
        conc = analysis_result.market_concentration
        print(f"   –¢–æ–ø-5 —Ñ–æ–Ω–¥–æ–≤: {conc['top_5_share']}% —Ä—ã–Ω–∫–∞")
        print(f"   –¢–æ–ø-10 —Ñ–æ–Ω–¥–æ–≤: {conc['top_10_share']}% —Ä—ã–Ω–∫–∞")
        print(f"   –ò–Ω–¥–µ–∫—Å HHI: {conc['hhi_index']}")
        print(f"   –£—Ä–æ–≤–µ–Ω—å: {conc['concentration_level']}")
        
        print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º:")
        size_dist = analysis_result.size_distribution
        print(f"   –ú–µ–≥–∞-—Ñ–æ–Ω–¥—ã (>10–º–ª—Ä–¥): {size_dist['mega_funds']}")
        print(f"   –ö—Ä—É–ø–Ω—ã–µ (1-10–º–ª—Ä–¥): {size_dist['large_funds']}")
        print(f"   –°—Ä–µ–¥–Ω–∏–µ (100–º–ª–Ω-1–º–ª—Ä–¥): {size_dist['medium_funds']}")
        print(f"   –ú–∞–ª—ã–µ (10-100–º–ª–Ω): {size_dist['small_funds']}")
        print(f"   –ú–∏–∫—Ä–æ (<10–º–ª–Ω): {size_dist['micro_funds']}")
        
        print(f"\nüèÜ –¢–æ–ø-10 –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö —Ñ–æ–Ω–¥–æ–≤:")
        for i, fund in enumerate(analysis_result.largest_funds[:10], 1):
            size_bil = fund['market_cap'] / 1_000_000_000
            print(f"   {i:2d}. {fund['ticker']}: {size_bil:.2f} –º–ª—Ä–¥ —Ä—É–±. ({fund['annual_return']:+.1f}%)")
        
        print(f"\nüìà –¢–æ–ø-5 –ª–∏–¥–µ—Ä–æ–≤ —Ä–æ—Å—Ç–∞:")
        for i, fund in enumerate(analysis_result.growth_leaders[:5], 1):
            size_mil = fund['market_cap'] / 1_000_000
            print(f"   {i}. {fund['ticker']}: {fund['annual_return']:+.1f}% ({size_mil:.0f} –º–ª–Ω —Ä—É–±.)")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–Ω—Å–∞–π—Ç—ã
        insights = analyzer.generate_nav_insights(analysis_result)
        print(f"\nüí° –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:")
        for insight in insights:
            print(f"   ‚Ä¢ {insight}")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
        print(f"\nüîç –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤...")
        trends = analyzer.analyze_size_trends(etf_data, [])
        
        if 'category_breakdown' in trends and trends['category_breakdown']:
            print(f"\nüè∑Ô∏è –¢–æ–ø-3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É:")
            category_data = trends['category_breakdown']
            sorted_categories = sorted(
                category_data.items(), 
                key=lambda x: x[1].get('total_cap', 0), 
                reverse=True
            )
            
            for i, (category, data) in enumerate(sorted_categories[:3], 1):
                total_bil = data.get('total_cap', 0) / 1_000_000_000
                funds_count = data.get('funds_count', 0)
                market_share = data.get('market_share', 0)
                print(f"   {i}. {category}: {total_bil:.1f} –º–ª—Ä–¥ —Ä—É–±. ({funds_count} —Ñ–æ–Ω–¥–æ–≤, {market_share:.1f}%)")
        
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –°–ß–ê –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –°–ß–ê: {e}")

if __name__ == "__main__":
    main()