#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞—à–±–æ—Ä–¥–∞ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –¥—Ä—É–≥–∏—Ö –ü–ö
–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ —Å–æ–∑–¥–∞–µ—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import json
import pandas as pd
import requests
from datetime import datetime, timedelta
from pathlib import Path
import time

class DashboardSetup:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        self.base_path = Path.cwd()
        
    def check_dependencies(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
        
        required_packages = [
            'flask', 'pandas', 'numpy', 'plotly', 'requests'
        ]
        
        missing_packages = []
        for package in required_packages:
            try:
                __import__(package)
                print(f"‚úÖ {package} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            except ImportError:
                missing_packages.append(package)
                print(f"‚ùå {package} –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù")
        
        if missing_packages:
            print(f"\n‚ö†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–∞–∫–µ—Ç—ã:")
            print(f"pip install {' '.join(missing_packages)}")
            return False
            
        return True
    
    def create_minimal_data_files(self):
        """–°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–±–æ—Ç—ã –¥–∞—à–±–æ—Ä–¥–∞"""
        print("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ñ–∞–π–ª ETF –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
        etf_data = {
            '–¢–∏–∫–µ—Ä': ['LQDT', 'TMOS', 'SBMX', 'AKBP', 'AKCB', 'AKGP', 'SBGB'],
            '–ù–∞–∑–≤–∞–Ω–∏–µ': [
                '–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å. –î–µ–Ω–µ–∂–Ω—ã–π —Ä—ã–Ω–æ–∫',
                '–ö–∞–∑–Ω–∞—á–µ–π—Å–∫–∏–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏',  
                '–°–º–µ—à–∞–Ω–Ω—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏',
                '–ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π —Å–µ–∫—Ç–æ—Ä',
                '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏',
                '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏',
                '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏'
            ],
            '–¢–∏–ø –∞–∫—Ç–∏–≤–∞': ['–û–±–ª–∏–≥–∞—Ü–∏–∏', '–û–±–ª–∏–≥–∞—Ü–∏–∏', '–û–±–ª–∏–≥–∞—Ü–∏–∏', '–ê–∫—Ü–∏–∏', '–û–±–ª–∏–≥–∞—Ü–∏–∏', '–û–±–ª–∏–≥–∞—Ü–∏–∏', '–û–±–ª–∏–≥–∞—Ü–∏–∏'],
            '–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —á–∏—Å—Ç—ã—Ö –∞–∫—Ç–∏–≤–æ–≤': [100000000, 50000000, 30000000, 20000000, 15000000, 12000000, 10000000],
            'annual_return': [15.5, 12.3, 8.7, -5.2, 14.1, 13.8, 12.9],  # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
            'volatility': [2.1, 3.5, 4.2, 18.5, 3.1, 2.8, 3.2],  # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
            '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è': ['–†–æ—Å—Å–∏—è', '–†–æ—Å—Å–∏—è', '–†–æ—Å—Å–∏—è', '–†–æ—Å—Å–∏—è', '–†–æ—Å—Å–∏—è', '–†–æ—Å—Å–∏—è', '–†–æ—Å—Å–∏—è'],
            '–ö–æ–º–∏—Å—Å–∏—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è': [0.3, 0.5, 0.4, 0.8, 0.4, 0.3, 0.4],
            'bid_ask_spread': [0.1, 0.15, 0.2, 0.3, 0.18, 0.12, 0.14],  # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
            'sharpe_ratio': [7.35, 3.51, 2.14, -1.09, 4.55, 4.21, 4.03]  # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
        }
        
        df = pd.DataFrame(etf_data)
        filename = 'enhanced_etf_data_20250827_105019.csv'
        df.to_csv(filename, index=False, encoding='utf-8')
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω {filename}")
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.create_classification_files(df)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.create_temporal_analysis_file()
        
    def create_classification_files(self, df):
        """–°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        print("üìã –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ë–ü–ò–§
        bpif_structure = df.copy()
        bpif_structure['–£—Ä–æ–≤–µ–Ω—å 1'] = bpif_structure['–¢–∏–ø –∞–∫—Ç–∏–≤–∞']
        bpif_structure['–£—Ä–æ–≤–µ–Ω—å 2'] = bpif_structure['–ù–∞–∑–≤–∞–Ω–∏–µ']
        
        filename = 'simplified_bpif_structure_20250827_105516.csv'
        bpif_structure.to_csv(filename, index=False, encoding='utf-8')
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω {filename}")
        
        # –°–≤–æ–¥–∫–∞ —É—Ä–æ–≤–Ω—è 1
        level1_summary = df.groupby('–¢–∏–ø –∞–∫—Ç–∏–≤–∞').agg({
            '–¢–∏–∫–µ—Ä': 'count',
            '–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —á–∏—Å—Ç—ã—Ö –∞–∫—Ç–∏–≤–æ–≤': 'sum',
            'annual_return': 'mean'
        }).reset_index()
        level1_summary.columns = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–Ω–¥–æ–≤', '–û–±—â–∏–µ –∞–∫—Ç–∏–≤—ã', '–°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å']
        
        filename = 'simplified_level1_summary_20250827_105516.csv'
        level1_summary.to_csv(filename, index=False, encoding='utf-8')
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω {filename}")
        
        # –°–≤–æ–¥–∫–∞ —É—Ä–æ–≤–Ω—è 2 
        level2_summary = df.groupby(['–¢–∏–ø –∞–∫—Ç–∏–≤–∞', '–ù–∞–∑–≤–∞–Ω–∏–µ']).agg({
            '–¢–∏–∫–µ—Ä': 'count',
            '–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —á–∏—Å—Ç—ã—Ö –∞–∫—Ç–∏–≤–æ–≤': 'sum'
        }).reset_index()
        level2_summary.columns = ['–£—Ä–æ–≤–µ–Ω—å 1', '–£—Ä–æ–≤–µ–Ω—å 2', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–Ω–¥–æ–≤', '–û–±—â–∏–µ –∞–∫—Ç–∏–≤—ã']
        
        filename = 'simplified_level2_summary_20250827_105516.csv'
        level2_summary.to_csv(filename, index=False, encoding='utf-8')
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω {filename}")
        
        # –ì–µ–æ–≥—Ä–∞—Ñ–∏—è —Å–≤–æ–¥–∫–∞
        geo_summary = df.groupby('–ì–µ–æ–≥—Ä–∞—Ñ–∏—è').agg({
            '–¢–∏–∫–µ—Ä': 'count',
            '–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —á–∏—Å—Ç—ã—Ö –∞–∫—Ç–∏–≤–æ–≤': 'sum'
        }).reset_index()
        geo_summary.columns = ['–ì–µ–æ–≥—Ä–∞—Ñ–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–Ω–¥–æ–≤', '–û–±—â–∏–µ –∞–∫—Ç–∏–≤—ã']
        
        filename = 'simplified_geography_summary_20250827_105516.csv'
        geo_summary.to_csv(filename, index=False, encoding='utf-8')
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω {filename}")
    
    def create_temporal_analysis_file(self):
        """–°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print("üìà –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
        
        temporal_data = {
            "6 –º–µ—Å—è—Ü–µ–≤": [
                {
                    "ticker": "LQDT",
                    "asset_type": "–û–±–ª–∏–≥–∞—Ü–∏–∏",
                    "return_pct": 7.8,
                    "volatility": 2.1,
                    "records": 120,
                    "nav": 100000000,
                    "first_date": "2025-02-28",
                    "last_date": "2025-08-28"
                },
                {
                    "ticker": "TMOS", 
                    "asset_type": "–û–±–ª–∏–≥–∞—Ü–∏–∏",
                    "return_pct": 6.5,
                    "volatility": 3.5,
                    "records": 118,
                    "nav": 50000000,
                    "first_date": "2025-02-28",
                    "last_date": "2025-08-28"
                }
            ],
            "3 –º–µ—Å—è—Ü–∞": [
                {
                    "ticker": "LQDT",
                    "asset_type": "–û–±–ª–∏–≥–∞—Ü–∏–∏", 
                    "return_pct": 3.9,
                    "volatility": 2.0,
                    "records": 60,
                    "nav": 100000000,
                    "first_date": "2025-05-28",
                    "last_date": "2025-08-28"
                }
            ],
            "1 –º–µ—Å—è—Ü": [
                {
                    "ticker": "LQDT",
                    "asset_type": "–û–±–ª–∏–≥–∞—Ü–∏–∏",
                    "return_pct": 1.3,
                    "volatility": 1.8,
                    "records": 20,
                    "nav": 100000000,
                    "first_date": "2025-07-28", 
                    "last_date": "2025-08-28"
                }
            ]
        }
        
        filename = 'real_temporal_analysis.json'
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(temporal_data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω {filename}")
        
    def create_directories(self):
        """–°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        print("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π...")
        
        directories = [
            'investfunds_cache',
            'cache', 
            'logs',
            'data',
            'templates'
        ]
        
        for directory in directories:
            Path(directory).mkdir(exist_ok=True)
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory}")
    
    def run_setup(self):
        """–ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É"""
        print("üöÄ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê –î–ê–®–ë–û–†–î–ê")
        print("=" * 60)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        if not self.check_dependencies():
            return False
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.create_directories()
        
        # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö
        self.create_minimal_data_files()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –≥–æ—Ç–æ–≤–æ
        self.verify_setup()
        
        print(f"\nüéâ –ù–ê–°–¢–†–û–ô–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"üìã –î–ª—è –∑–∞–ø—É—Å–∫–∞ –¥–∞—à–±–æ—Ä–¥–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
        print(f"   python3 simple_dashboard.py")
        print(f"üåê –î–∞—à–±–æ—Ä–¥ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: http://localhost:5004")
        
        return True
        
    def verify_setup(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"""
        print(f"\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏...")
        
        required_files = [
            'enhanced_etf_data_20250827_105019.csv',
            'simplified_bpif_structure_20250827_105516.csv',
            'simplified_level1_summary_20250827_105516.csv',
            'simplified_level2_summary_20250827_105516.csv',
            'simplified_geography_summary_20250827_105516.csv',
            'real_temporal_analysis.json'
        ]
        
        all_good = True
        for file in required_files:
            if Path(file).exists():
                size = Path(file).stat().st_size
                print(f"‚úÖ {file} ({size} –±–∞–π—Ç)")
            else:
                print(f"‚ùå {file} –ù–ï –ù–ê–ô–î–ï–ù")
                all_good = False
        
        if all_good:
            print("‚úÖ –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã!")
        else:
            print("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∞–π–ª—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        return all_good

def main():
    setup = DashboardSetup()
    success = setup.run_setup()
    
    if success:
        sys.exit(0)
    else:
        print("‚ùå –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
        sys.exit(1)

if __name__ == "__main__":
    main()