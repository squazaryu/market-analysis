#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —Ñ–æ–Ω–¥—ã —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –∏–∑ –≥—Ä—É–ø–ø—ã "—Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
"""

import pandas as pd
import json
from pathlib import Path
from investfunds_parser import InvestFundsParser
import re

def auto_add_high_confidence_funds(min_confidence=0.75):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —Ñ–æ–Ω–¥—ã —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    try:
        results_df = pd.read_csv('fund_mapping_results.csv')
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
        return
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    high_confidence = results_df[
        (results_df['status'] == 'needs_review') & 
        (results_df['confidence'] >= min_confidence)
    ]
    
    if high_confidence.empty:
        print(f"‚ùå –ù–µ—Ç —Ñ–æ–Ω–¥–æ–≤ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é >= {min_confidence}")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–∞–ø–ø–∏–Ω–≥
    try:
        with open('auto_fund_mapping.json', 'r', encoding='utf-8') as f:
            mapping_data = json.load(f)
            current_mapping = mapping_data.get('mapping', {})
    except:
        current_mapping = {}
    
    print(f"ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–æ–Ω–¥–æ–≤ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é >= {min_confidence}")
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(high_confidence)}")
    
    added_count = 0
    verified_count = 0
    
    parser = InvestFundsParser()
    
    for _, row in high_confidence.iterrows():
        ticker = row['ticker']
        fund_id = row['best_match_id']
        confidence = row['confidence']
        found_name = row['best_match_name']
        
        print(f"\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º {ticker} (ID: {fund_id}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
        
        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        try:
            fund_data = parser.get_fund_data(fund_id, use_cache=False)
            
            if fund_data and fund_data.get('nav', 0) > 0:
                nav_billions = fund_data['nav'] / 1e9
                unit_price = fund_data['unit_price']
                
                print(f"   üìä –°–ß–ê: {nav_billions:.2f} –º–ª—Ä–¥ —Ä—É–±., –¶–µ–Ω–∞ –ø–∞—è: {unit_price:.4f}")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - —Ç–∏–∫–µ—Ä –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∏–ª–∏ –≤—ã—Å–æ–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
                name_contains_ticker = ticker.upper() in found_name.upper()
                
                if name_contains_ticker or confidence >= 0.85:
                    current_mapping[ticker] = fund_id
                    added_count += 1
                    print(f"   ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω: {ticker} -> {fund_id}")
                else:
                    print(f"   ‚ö†Ô∏è  –¢—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Ç–∏–∫–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏)")
                
                verified_count += 1
            else:
                print(f"   ‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –Ω—É–ª–µ–≤–∞—è –°–ß–ê")
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥
    if added_count > 0:
        updated_data = {
            'mapping': current_mapping,
            'stats': {
                'total_mapped': len(current_mapping),
                'auto_added_high_conf': added_count,
                'verified_funds': verified_count
            },
            'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        with open('auto_fund_mapping.json', 'w', encoding='utf-8') as f:
            json.dump(updated_data, f, indent=2, ensure_ascii=False)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º investfunds_parser.py
        update_parser_mapping(current_mapping)
        
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {added_count}")
        print(f"   üîç –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {verified_count}")
        print(f"   üìä –í—Å–µ–≥–æ –∑–∞–º–∞–ø–ª–µ–Ω–æ: {len(current_mapping)}/96 = {len(current_mapping)/96*100:.1f}%")
    else:
        print(f"\nüìù –ù–µ—Ç —Ñ–æ–Ω–¥–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")

def update_parser_mapping(mapping):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –≤ investfunds_parser.py"""
    
    parser_file = Path('investfunds_parser.py')
    
    if not parser_file.exists():
        print("‚ùå –§–∞–π–ª investfunds_parser.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    with open(parser_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –º–∞–ø–ø–∏–Ω–≥ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
    mapping_lines = []
    mapping_lines.append("        # –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–∫–µ—Ä–æ–≤ –Ω–∞ ID —Ñ–æ–Ω–¥–æ–≤ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω)")
    mapping_lines.append("        self.fund_mapping = {")
    
    for ticker, fund_id in sorted(mapping.items()):
        mapping_lines.append(f"            '{ticker}': {fund_id},")
    
    mapping_lines.append("        }")
    
    new_mapping_text = "\n".join(mapping_lines)
    
    # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π –º–∞–ø–ø–∏–Ω–≥
    pattern = r'# –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–∫–µ—Ä–æ–≤ –Ω–∞ ID —Ñ–æ–Ω–¥–æ–≤.*?self\.fund_mapping = \{[^}]*\}'
    
    new_content = re.sub(
        pattern,
        new_mapping_text,
        content,
        flags=re.DOTALL
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    with open(parser_file, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print(f"üîÑ –§–∞–π–ª investfunds_parser.py –æ–±–Ω–æ–≤–ª–µ–Ω —Å {len(mapping)} —Ñ–æ–Ω–¥–∞–º–∏")

if __name__ == "__main__":
    auto_add_high_confidence_funds(min_confidence=0.75)