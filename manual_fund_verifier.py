#!/usr/bin/env python3
"""
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–æ–Ω–¥–æ–≤ –∏–∑ –≥—Ä—É–ø–ø—ã "—Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
"""

import pandas as pd
import json
from pathlib import Path
from investfunds_parser import InvestFundsParser

def load_review_candidates():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    
    try:
        results_df = pd.read_csv('fund_mapping_results.csv')
        return results_df[results_df['status'] == 'needs_review']
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
        return pd.DataFrame()

def verify_fund_manually(ticker, fund_id, expected_name, found_name):
    """–†—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ–Ω–¥–∞"""
    
    parser = InvestFundsParser()
    
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ–Ω–¥: {ticker}")
    print(f"üìù –û–∂–∏–¥–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {expected_name}")
    print(f"üåê –ù–∞–π–¥–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {found_name}")
    print(f"üÜî –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π ID: {fund_id}")
    print(f"üîó URL: https://investfunds.ru/funds/{fund_id}/")
    
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
    try:
        fund_data = parser.get_fund_data(fund_id, use_cache=False)
        
        if fund_data:
            print(f"\nüìä –î–∞–Ω–Ω—ã–µ —Å —Å–∞–π—Ç–∞:")
            print(f"   üí∞ –°–ß–ê: {fund_data['nav']/1e9:.2f} –º–ª—Ä–¥ —Ä—É–±.")
            print(f"   üíµ –¶–µ–Ω–∞ –ø–∞—è: {fund_data['unit_price']:.4f} —Ä—É–±.")
            print(f"   üìÖ –î–∞—Ç–∞: {fund_data['date']}")
        else:
            print(f"\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è ID {fund_id}")
            
    except Exception as e:
        print(f"\n‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    print(f"\n–í–∞—Ä–∏–∞–Ω—Ç—ã:")
    print(f"  y - –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –º–∞–ø–ø–∏–Ω–≥")
    print(f"  n - –æ—Ç–∫–ª–æ–Ω–∏—Ç—å")
    print(f"  s - –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å (—Ä–µ—à–∏—Ç—å –ø–æ–∑–∂–µ)")
    print(f"  id - –≤–≤–µ—Å—Ç–∏ –¥—Ä—É–≥–æ–π ID")
    
    choice = input("–í–∞—à –≤—ã–±–æ—Ä: ").strip().lower()
    
    if choice == 'y':
        return fund_id
    elif choice == 'n':
        return None
    elif choice == 's':
        return 'skip'
    elif choice.startswith('id'):
        try:
            new_id = int(choice.split()[-1]) if len(choice.split()) > 1 else int(input("–í–≤–µ–¥–∏—Ç–µ ID: "))
            return new_id
        except ValueError:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ID")
            return 'skip'
    else:
        return 'skip'

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üîç –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–æ–Ω–¥–æ–≤")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    candidates = load_review_candidates()
    
    if candidates.empty:
        print("‚ùå –ù–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        return
    
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(candidates)} —Ñ–æ–Ω–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–∞–ø–ø–∏–Ω–≥
    try:
        with open('auto_fund_mapping.json', 'r', encoding='utf-8') as f:
            mapping_data = json.load(f)
            current_mapping = mapping_data.get('mapping', {})
    except:
        current_mapping = {}
    
    new_mappings = {}
    skipped = []
    
    for idx, row in candidates.iterrows():
        ticker = row['ticker']
        fund_id = row['best_match_id']
        expected_name = row['search_name']
        found_name = row['best_match_name']
        confidence = row['confidence']
        
        print(f"\n{'='*60}")
        print(f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {idx-candidates.index[0]+1}/{len(candidates)}")
        print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}")
        
        result = verify_fund_manually(ticker, fund_id, expected_name, found_name)
        
        if result == 'skip':
            skipped.append(ticker)
            print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω: {ticker}")
        elif result is None:
            print(f"‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω: {ticker}")
        elif isinstance(result, int):
            new_mappings[ticker] = result
            print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω: {ticker} -> {result}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥
    if new_mappings:
        current_mapping.update(new_mappings)
        
        updated_data = {
            'mapping': current_mapping,
            'stats': {
                'total_mapped': len(current_mapping),
                'manually_verified': len(new_mappings),
                'auto_mapped': len(current_mapping) - len(new_mappings)
            },
            'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        with open('auto_fund_mapping.json', 'w', encoding='utf-8') as f:
            json.dump(updated_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ –ú–∞–ø–ø–∏–Ω–≥ –æ–±–Ω–æ–≤–ª–µ–Ω!")
        print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {len(new_mappings)} —Ñ–æ–Ω–¥–æ–≤")
        print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {len(skipped)} —Ñ–æ–Ω–¥–æ–≤")
        print(f"   üìä –í—Å–µ–≥–æ –∑–∞–º–∞–ø–ª–µ–Ω–æ: {len(current_mapping)}/96 = {len(current_mapping)/96*100:.1f}%")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º investfunds_parser.py
        print(f"\nüîÑ –û–±–Ω–æ–≤–ª—è–µ–º investfunds_parser.py...")
        update_parser_mapping(current_mapping)
        
    else:
        print(f"\nüìù –ù–æ–≤—ã—Ö –º–∞–ø–ø–∏–Ω–≥–æ–≤ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ")
    
    if skipped:
        print(f"\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Ñ–æ–Ω–¥—ã: {', '.join(skipped)}")

def update_parser_mapping(mapping):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –≤ investfunds_parser.py"""
    
    parser_file = Path('investfunds_parser.py')
    
    if not parser_file.exists():
        print("‚ùå –§–∞–π–ª investfunds_parser.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    with open(parser_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –º–∞–ø–ø–∏–Ω–≥
    mapping_lines = []
    mapping_lines.append("        # –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–∫–µ—Ä–æ–≤ –Ω–∞ ID —Ñ–æ–Ω–¥–æ–≤ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω)")
    mapping_lines.append("        self.fund_mapping = {")
    
    for ticker, fund_id in sorted(mapping.items()):
        mapping_lines.append(f"            '{ticker}': {fund_id},")
    
    mapping_lines.append("        }")
    
    new_mapping_text = "\n".join(mapping_lines)
    
    # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π –º–∞–ø–ø–∏–Ω–≥
    import re
    pattern = r'# –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–∫–µ—Ä–æ–≤ –Ω–∞ ID —Ñ–æ–Ω–¥–æ–≤.*?self\.fund_mapping = \{[^}]*\}'
    
    new_content = re.sub(
        pattern,
        new_mapping_text,
        content,
        flags=re.DOTALL
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    with open(parser_file, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print(f"‚úÖ –§–∞–π–ª investfunds_parser.py –æ–±–Ω–æ–≤–ª–µ–Ω —Å {len(mapping)} —Ñ–æ–Ω–¥–∞–º–∏")

if __name__ == "__main__":
    main()