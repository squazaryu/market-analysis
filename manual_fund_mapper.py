#!/usr/bin/env python3
"""
–†—É—á–Ω–æ–π –º–∞–ø–ø–µ—Ä —Ñ–æ–Ω–¥–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
–ë–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –ø–æ–∫—Ä—ã—Ç–∏—è
"""

import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import json
from pathlib import Path
import time
from typing import Dict, List, Optional

class ManualFundMapper:
    """–†—É—á–Ω–æ–π –º–∞–ø–ø–µ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Ñ–æ–Ω–¥–æ–≤"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        self.base_url = "https://investfunds.ru"
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö –º–∞–ø–ø–∏–Ω–≥–æ–≤
        # –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã ID –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
        self.candidate_mappings = {
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ
            'LQDT': 5973,   # –í–ò–ú –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
            'AKMB': 6225,   # –ê–ª—å—Ñ–∞-–ö–∞–ø–∏—Ç–∞–ª –£–ø—Ä–∞–≤–ª—è–µ–º—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏  
            'AKGD': 10147,  # –ê-–ö–∞–ø–∏—Ç–∞–ª –ó–æ–ª–æ—Ç–æ
            
            # –ê–ª—å—Ñ–∞-–ö–∞–ø–∏—Ç–∞–ª —Ñ–æ–Ω–¥—ã (–≤–µ—Ä–æ—è—Ç–Ω–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 6000-7000, 10000-12000)
            'AKMM': 6200,   # –í–æ–∑–º–æ–∂–Ω–æ –¥–µ–Ω–µ–∂–Ω—ã–π —Ä—ã–Ω–æ–∫
            'AKFT': 6250,   # –í–æ–∑–º–æ–∂–Ω–æ —Ñ–ª–æ–∞—Ç–µ—Ä—ã
            'AMGL': 12445,  # –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (—É–∂–µ –≤ —Å—Ç–∞—Ä–æ–º –º–∞–ø–ø–∏–Ω–≥–µ)
            'AMNR': 10053,  # –ê–º–µ—Ä–∏–∫–∞ (—É–∂–µ –≤ —Å—Ç–∞—Ä–æ–º –º–∞–ø–ø–∏–Ω–≥–µ)
            'AMNY': 10613,  # –î–æ–ª–ª–∞—Ä –°–®–ê (—É–∂–µ –≤ —Å—Ç–∞—Ä–æ–º –º–∞–ø–ø–∏–Ω–≥–µ)
            'AMRE': 6809,   # –†–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏ (—É–∂–µ –≤ —Å—Ç–∞—Ä–æ–º –º–∞–ø–ø–∏–Ω–≥–µ)
            
            # –°–±–µ—Ä–±–∞–Ω–∫ –ê–ú —Ñ–æ–Ω–¥—ã (–≤–æ–∑–º–æ–∂–Ω–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 1000-3000)
            'SBMM': 1500,   # –°–±–µ—Ä–±–∞–Ω–∫ –¥–µ–Ω–µ–∂–Ω—ã–π —Ä—ã–Ω–æ–∫
            'SBGB': 1600,   # –°–±–µ—Ä–±–∞–Ω–∫ –≥–æ—Å–æ–±–ª–∏–≥–∞—Ü–∏–∏
            'SBCB': 1700,   # –°–±–µ—Ä–±–∞–Ω–∫ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏
            'SBER': 1800,   # –°–±–µ—Ä–±–∞–Ω–∫ –∞–∫—Ü–∏–∏
            
            # –¢-–ö–∞–ø–∏—Ç–∞–ª (–¢–∏–Ω—å–∫–æ—Ñ—Ñ) —Ñ–æ–Ω–¥—ã (–≤–æ–∑–º–æ–∂–Ω–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 8000-9000)
            'TMOS': 8100,   # –¢–∏–Ω—å–∫–æ—Ñ—Ñ –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –±–∏—Ä–∂–∞
            'TGLD': 8200,   # –¢–∏–Ω—å–∫–æ—Ñ—Ñ –∑–æ–ª–æ—Ç–æ
            'TBRU': 8300,   # –¢–∏–Ω—å–∫–æ—Ñ—Ñ —Ä—É–±–ª–µ–≤—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏
            'TBEU': 8400,   # –¢–∏–Ω—å–∫–æ—Ñ—Ñ –µ–≤—Ä–æ–æ–±–ª–∏–≥–∞—Ü–∏–∏
            'TCSG': 8500,   # –¢–∏–Ω—å–∫–æ—Ñ—Ñ —Ç–µ—Ö—Å–µ–∫—Ç–æ—Ä
            
            # –í–¢–ë –ö–∞–ø–∏—Ç–∞–ª —Ñ–æ–Ω–¥—ã (–≤–æ–∑–º–æ–∂–Ω–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 3000-4000)
            'VTBM': 3100,   # –í–¢–ë –¥–µ–Ω–µ–∂–Ω—ã–π —Ä—ã–Ω–æ–∫
            'VTBR': 3200,   # –í–¢–ë —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏
            'VTBB': 3300,   # –í–¢–ë –æ–±–ª–∏–≥–∞—Ü–∏–∏
            
            # –ê–ö –ë–ê–†–° —Ñ–æ–Ω–¥—ã (–≤–æ–∑–º–æ–∂–Ω–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 11000-12000)
            'BCSD': 11499,  # –ê–ö –ë–ê–†–° –¥–µ–Ω–µ–∂–Ω—ã–π —Ä—ã–Ω–æ–∫ (—É–∂–µ –≤ —Å—Ç–∞—Ä–æ–º –º–∞–ø–ø–∏–Ω–≥–µ)
            'MONY': 11500,  # –î–µ–Ω—å–≥–∏
            'BCSG': 11600,  # –ê–ö –ë–ê–†–° –≥–æ—Å–æ–±–ª–∏–≥–∞—Ü–∏–∏
            'BCSR': 11700,  # –ê–ö –ë–ê–†–° —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏
        }
    
    def verify_fund_mapping(self, ticker: str, fund_id: int) -> Optional[Dict]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–∞–ø–ø–∏–Ω–≥ —Ç–∏–∫–µ—Ä–∞ –Ω–∞ ID —Ñ–æ–Ω–¥–∞"""
        
        try:
            print(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º {ticker} -> ID {fund_id}")
            
            url = f"{self.base_url}/funds/{fund_id}/"
            response = self.session.get(url, timeout=15)
            
            if response.status_code != 200:
                print(f"‚ùå {ticker}: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (—Å—Ç–∞—Ç—É—Å {response.status_code})")
                return None
            
            soup = BeautifulSoup(response.content, 'html.parser')
            page_text = soup.get_text().upper()
            
            # –ò—â–µ–º —Ç–∏–∫–µ—Ä –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            ticker_patterns = [
                ticker.upper(),
                f"–ë–ü–ò–§ {ticker.upper()}",
                f"ETF {ticker.upper()}",
                f"{ticker.upper()} ",
                f" {ticker.upper()}",
                f"({ticker.upper()})",
                f"[{ticker.upper()}]",
            ]
            
            ticker_found = any(pattern in page_text for pattern in ticker_patterns)
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–æ–Ω–¥–∞
            title = soup.find('h1')
            fund_name = title.get_text(strip=True) if title else 'Unknown'
            
            if ticker_found:
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –°–ß–ê –∏ —Ü–µ–Ω—É –ø–∞—è
                nav_value = self._extract_nav_from_page(page_text)
                unit_price = self._extract_unit_price_from_page(page_text)
                
                print(f"‚úÖ {ticker}: –Ω–∞–π–¥–µ–Ω! –°–ß–ê: {nav_value/1e9 if nav_value else 0:.1f} –º–ª—Ä–¥ ‚ÇΩ")
                
                return {
                    'ticker': ticker,
                    'fund_id': fund_id,
                    'name': fund_name,
                    'nav': nav_value or 0,
                    'unit_price': unit_price or 0,
                    'url': url,
                    'verified': True
                }
            else:
                print(f"‚ö†Ô∏è {ticker}: ID {fund_id} —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–∏–∫–µ—Ä")
                print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {fund_name[:60]}...")
                return None
                
        except Exception as e:
            print(f"‚ùå {ticker}: –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ ID {fund_id}: {e}")
            return None
    
    def _extract_nav_from_page(self, page_text: str) -> Optional[float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –°–ß–ê —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –°–ß–ê
        nav_patterns = [
            r'–°–ß–ê[:\s]*([0-9\s,]+(?:\.\d+)?)',
            r'—á–∏—Å—Ç—ã—Ö –∞–∫—Ç–∏–≤–æ–≤[:\s]*([0-9\s,]+(?:\.\d+)?)',
            r'Net Asset Value[:\s]*([0-9\s,]+(?:\.\d+)?)',
            r'(\d{1,3}(?:\s\d{3})+(?:\s\d{3})*(?:\.\d+)?)',  # –ß–∏—Å–ª–∞ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Ç—ã—Å—è—á
        ]
        
        for pattern in nav_patterns:
            matches = re.findall(pattern, page_text, re.IGNORECASE)
            for match in matches:
                try:
                    # –û—á–∏—â–∞–µ–º —á–∏—Å–ª–æ - —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ
                    cleaned = re.sub(r'[^\d.]', '', match.replace(' ', '').replace(',', ''))
                    if cleaned:
                        value = float(cleaned)
                        # –°–ß–ê –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ 1 –º–ª–Ω —Ä—É–±–ª–µ–π
                        if value > 1_000_000:
                            return value
                except ValueError:
                    continue
        
        return None
    
    def _extract_unit_price_from_page(self, page_text: str) -> Optional[float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –ø–∞—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        
        price_patterns = [
            r'—Ü–µ–Ω–∞ –ø–∞—è[:\s]*([0-9.,]+)',
            r'—Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–∞—è[:\s]*([0-9.,]+)',
            r'unit price[:\s]*([0-9.,]+)',
        ]
        
        for pattern in price_patterns:
            matches = re.findall(pattern, page_text, re.IGNORECASE)
            for match in matches:
                try:
                    cleaned = re.sub(r'[^\d.]', '', match.replace(',', '.'))
                    if cleaned:
                        value = float(cleaned)
                        if 0.1 <= value <= 10000:
                            return value
                except ValueError:
                    continue
        
        return None
    
    def verify_all_candidates(self) -> Dict[str, Dict]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ –º–∞–ø–ø–∏–Ω–≥"""
        
        print(f"üéØ –ü—Ä–æ–≤–µ—Ä—è–µ–º {len(self.candidate_mappings)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –º–∞–ø–ø–∏–Ω–≥")
        print("=" * 60)
        
        verified_mappings = {}
        
        for ticker, fund_id in self.candidate_mappings.items():
            result = self.verify_fund_mapping(ticker, fund_id)
            
            if result:
                verified_mappings[ticker] = result
            
            time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            print()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        
        return verified_mappings
    
    def create_priority_list(self, etf_data: pd.DataFrame) -> List[str]:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞"""
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏/–æ–±—ä–µ–º—É —Ç–æ—Ä–≥–æ–≤
        if 'avg_daily_value_rub' in etf_data.columns:
            sorted_etf = etf_data.sort_values('avg_daily_value_rub', ascending=False)
        else:
            sorted_etf = etf_data
        
        return sorted_etf['ticker'].tolist()
    
    def interactive_mapping(self, etf_data: pd.DataFrame):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –º–∞–ø–ø–∏–Ω–≥–∞"""
        
        priority_tickers = self.create_priority_list(etf_data)
        verified_mappings = {}
        
        print("üéØ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –ú–ê–ü–ü–ò–ù–ì –§–û–ù–î–û–í")
        print("–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ ID –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        print("=" * 60)
        
        for ticker in priority_tickers[:20]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–º–∏ 20
            if ticker in self.candidate_mappings:
                continue  # –£–∂–µ –ø—Ä–æ–≤–µ—Ä–∏–ª–∏
            
            print(f"\nüîç –ò—â–µ–º {ticker}")
            
            # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º ID –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            suggested_ids = self._suggest_ids_for_ticker(ticker)
            
            found = False
            for fund_id in suggested_ids:
                result = self.verify_fund_mapping(ticker, fund_id)
                if result:
                    verified_mappings[ticker] = result
                    found = True
                    break
                
                time.sleep(0.5)
            
            if not found:
                print(f"‚ùå {ticker}: –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö ID")
        
        return verified_mappings
    
    def _suggest_ids_for_ticker(self, ticker: str) -> List[int]:
        """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω—ã–µ ID –¥–ª—è —Ç–∏–∫–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        
        suggestions = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ —Ç–∏–∫–µ—Ä–æ–≤
        if ticker.startswith('AK') or ticker.startswith('AM'):
            # –ê–ª—å—Ñ–∞-–ö–∞–ø–∏—Ç–∞–ª: –¥–∏–∞–ø–∞–∑–æ–Ω—ã 6000-7000, 10000-12000
            suggestions.extend([6000 + i*50 for i in range(20)])  # 6000-6950
            suggestions.extend([10000 + i*100 for i in range(20)]) # 10000-11900
            
        elif ticker.startswith('SB'):
            # –°–±–µ—Ä–±–∞–Ω–∫ –ê–ú: –¥–∏–∞–ø–∞–∑–æ–Ω 1000-3000
            suggestions.extend([1000 + i*100 for i in range(20)])  # 1000-2900
            
        elif ticker.startswith('T'):
            # –¢–∏–Ω—å–∫–æ—Ñ—Ñ: –¥–∏–∞–ø–∞–∑–æ–Ω 8000-9000
            suggestions.extend([8000 + i*50 for i in range(20)])   # 8000-8950
            
        elif ticker.startswith('VTB'):
            # –í–¢–ë: –¥–∏–∞–ø–∞–∑–æ–Ω 3000-4000
            suggestions.extend([3000 + i*50 for i in range(20)])   # 3000-3950
            
        elif ticker.startswith('BC') or ticker.startswith('MON'):
            # –ê–ö –ë–ê–†–°: –¥–∏–∞–ø–∞–∑–æ–Ω 11000-12000
            suggestions.extend([11000 + i*50 for i in range(20)])  # 11000-11950
            
        else:
            # –û–±—â–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã
            suggestions.extend([1000, 2000, 3000, 5000, 6000, 8000, 10000, 11000, 12000])
        
        return suggestions[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ ETF
    data_files = list(Path('.').glob('enhanced_etf_data_*.csv'))
    if not data_files:
        data_files = list(Path('.').glob('full_moex_etf_data_*.csv'))
    
    if not data_files:
        print("‚ùå –§–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ ETF –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    latest_data = max(data_files, key=lambda x: x.stat().st_mtime)
    etf_data = pd.read_csv(latest_data)
    
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(etf_data)} ETF")
    
    # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–µ—Ä
    mapper = ManualFundMapper()
    
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –º–∞–ø–ø–∏–Ω–≥")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
    verified_results = mapper.verify_all_candidates()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    save_data = {
        'timestamp': pd.Timestamp.now().isoformat(),
        'verified_mappings': len(verified_results),
        'total_candidates': len(mapper.candidate_mappings),
        'success_rate': len(verified_results) / len(mapper.candidate_mappings) * 100,
        'results': verified_results
    }
    
    with open('manual_mapping_results.json', 'w', encoding='utf-8') as f:
        json.dump(save_data, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nüéâ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –†–£–ß–ù–û–ì–û –ú–ê–ü–ü–ò–ù–ì–ê:")
    print(f"   üìä –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(mapper.candidate_mappings)}")
    print(f"   ‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ: {len(verified_results)}")
    print(f"   üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {len(verified_results)/len(mapper.candidate_mappings)*100:.1f}%")
    
    if verified_results:
        print(f"\nüèÜ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏:")
        verified_mapping = {}
        for ticker, data in verified_results.items():
            if data.get('nav', 0) > 0:
                verified_mapping[ticker] = data['fund_id']
                print(f"   {ticker} -> ID {data['fund_id']} (–°–ß–ê: {data['nav']/1e9:.1f} –º–ª—Ä–¥ ‚ÇΩ)")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ —Ä—ã–Ω–∫–∞
        total_nav = sum(data.get('nav', 0) for data in verified_results.values())
        print(f"\nüìä –ü–æ–∫—Ä—ã—Ç–∏–µ —Ä—ã–Ω–∫–∞:")
        print(f"   üí∞ –û–±—â–∞—è –°–ß–ê –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–æ–Ω–¥–æ–≤: {total_nav/1e9:.1f} –º–ª—Ä–¥ ‚ÇΩ")
        print(f"   üìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–æ–Ω–¥–æ–≤: {len(verified_mapping)}")
        
        print(f"\nüìã –ú–∞–ø–ø–∏–Ω–≥ –¥–ª—è investfunds_parser.py:")
        for ticker, fund_id in sorted(verified_mapping.items()):
            print(f"   '{ticker}': {fund_id},")
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ manual_mapping_results.json")

if __name__ == "__main__":
    main()